{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Importing the required modules**"
      ],
      "metadata": {
        "id": "VISWGdDWKeUc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5FIGu0rIQG3"
      },
      "outputs": [],
      "source": [
        "# Importing the NLTK library and Random module\n",
        "import nltk\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading all the NLTK files\n",
        "nltk.download_shell()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2EHKLtzIpwo",
        "outputId": "176f5443-ee5d-480d-cf90-585d574a3c61"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> all\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    Downloading collection 'all'\n",
            "       | \n",
            "       | Downloading package abc to /root/nltk_data...\n",
            "       |   Unzipping corpora/abc.zip.\n",
            "       | Downloading package alpino to /root/nltk_data...\n",
            "       |   Unzipping corpora/alpino.zip.\n",
            "       | Downloading package averaged_perceptron_tagger to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "       | Downloading package averaged_perceptron_tagger_ru to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping taggers/averaged_perceptron_tagger_ru.zip.\n",
            "       | Downloading package basque_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/basque_grammars.zip.\n",
            "       | Downloading package biocreative_ppi to /root/nltk_data...\n",
            "       |   Unzipping corpora/biocreative_ppi.zip.\n",
            "       | Downloading package bllip_wsj_no_aux to /root/nltk_data...\n",
            "       |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "       | Downloading package book_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/book_grammars.zip.\n",
            "       | Downloading package brown to /root/nltk_data...\n",
            "       |   Unzipping corpora/brown.zip.\n",
            "       | Downloading package brown_tei to /root/nltk_data...\n",
            "       |   Unzipping corpora/brown_tei.zip.\n",
            "       | Downloading package cess_cat to /root/nltk_data...\n",
            "       |   Unzipping corpora/cess_cat.zip.\n",
            "       | Downloading package cess_esp to /root/nltk_data...\n",
            "       |   Unzipping corpora/cess_esp.zip.\n",
            "       | Downloading package chat80 to /root/nltk_data...\n",
            "       |   Unzipping corpora/chat80.zip.\n",
            "       | Downloading package city_database to /root/nltk_data...\n",
            "       |   Unzipping corpora/city_database.zip.\n",
            "       | Downloading package cmudict to /root/nltk_data...\n",
            "       |   Unzipping corpora/cmudict.zip.\n",
            "       | Downloading package comparative_sentences to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping corpora/comparative_sentences.zip.\n",
            "       | Downloading package comtrans to /root/nltk_data...\n",
            "       | Downloading package conll2000 to /root/nltk_data...\n",
            "       |   Unzipping corpora/conll2000.zip.\n",
            "       | Downloading package conll2002 to /root/nltk_data...\n",
            "       |   Unzipping corpora/conll2002.zip.\n",
            "       | Downloading package conll2007 to /root/nltk_data...\n",
            "       | Downloading package crubadan to /root/nltk_data...\n",
            "       |   Unzipping corpora/crubadan.zip.\n",
            "       | Downloading package dependency_treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/dependency_treebank.zip.\n",
            "       | Downloading package dolch to /root/nltk_data...\n",
            "       |   Unzipping corpora/dolch.zip.\n",
            "       | Downloading package europarl_raw to /root/nltk_data...\n",
            "       |   Unzipping corpora/europarl_raw.zip.\n",
            "       | Downloading package extended_omw to /root/nltk_data...\n",
            "       | Downloading package floresta to /root/nltk_data...\n",
            "       |   Unzipping corpora/floresta.zip.\n",
            "       | Downloading package framenet_v15 to /root/nltk_data...\n",
            "       |   Unzipping corpora/framenet_v15.zip.\n",
            "       | Downloading package framenet_v17 to /root/nltk_data...\n",
            "       |   Unzipping corpora/framenet_v17.zip.\n",
            "       | Downloading package gazetteers to /root/nltk_data...\n",
            "       |   Unzipping corpora/gazetteers.zip.\n",
            "       | Downloading package genesis to /root/nltk_data...\n",
            "       |   Unzipping corpora/genesis.zip.\n",
            "       | Downloading package gutenberg to /root/nltk_data...\n",
            "       |   Unzipping corpora/gutenberg.zip.\n",
            "       | Downloading package ieer to /root/nltk_data...\n",
            "       |   Unzipping corpora/ieer.zip.\n",
            "       | Downloading package inaugural to /root/nltk_data...\n",
            "       |   Unzipping corpora/inaugural.zip.\n",
            "       | Downloading package indian to /root/nltk_data...\n",
            "       |   Unzipping corpora/indian.zip.\n",
            "       | Downloading package jeita to /root/nltk_data...\n",
            "       | Downloading package kimmo to /root/nltk_data...\n",
            "       |   Unzipping corpora/kimmo.zip.\n",
            "       | Downloading package knbc to /root/nltk_data...\n",
            "       | Downloading package large_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/large_grammars.zip.\n",
            "       | Downloading package lin_thesaurus to /root/nltk_data...\n",
            "       |   Unzipping corpora/lin_thesaurus.zip.\n",
            "       | Downloading package mac_morpho to /root/nltk_data...\n",
            "       |   Unzipping corpora/mac_morpho.zip.\n",
            "       | Downloading package machado to /root/nltk_data...\n",
            "       | Downloading package masc_tagged to /root/nltk_data...\n",
            "       | Downloading package maxent_ne_chunker to /root/nltk_data...\n",
            "       |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "       | Downloading package maxent_treebank_pos_tagger to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "       | Downloading package moses_sample to /root/nltk_data...\n",
            "       |   Unzipping models/moses_sample.zip.\n",
            "       | Downloading package movie_reviews to /root/nltk_data...\n",
            "       |   Unzipping corpora/movie_reviews.zip.\n",
            "       | Downloading package mte_teip5 to /root/nltk_data...\n",
            "       |   Unzipping corpora/mte_teip5.zip.\n",
            "       | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "       |   Unzipping misc/mwa_ppdb.zip.\n",
            "       | Downloading package names to /root/nltk_data...\n",
            "       |   Unzipping corpora/names.zip.\n",
            "       | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "       | Downloading package nonbreaking_prefixes to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "       | Downloading package nps_chat to /root/nltk_data...\n",
            "       |   Unzipping corpora/nps_chat.zip.\n",
            "       | Downloading package omw to /root/nltk_data...\n",
            "       | Downloading package omw-1.4 to /root/nltk_data...\n",
            "       | Downloading package opinion_lexicon to /root/nltk_data...\n",
            "       |   Unzipping corpora/opinion_lexicon.zip.\n",
            "       | Downloading package panlex_swadesh to /root/nltk_data...\n",
            "       | Downloading package paradigms to /root/nltk_data...\n",
            "       |   Unzipping corpora/paradigms.zip.\n",
            "       | Downloading package pe08 to /root/nltk_data...\n",
            "       |   Unzipping corpora/pe08.zip.\n",
            "       | Downloading package perluniprops to /root/nltk_data...\n",
            "       |   Unzipping misc/perluniprops.zip.\n",
            "       | Downloading package pil to /root/nltk_data...\n",
            "       |   Unzipping corpora/pil.zip.\n",
            "       | Downloading package pl196x to /root/nltk_data...\n",
            "       |   Unzipping corpora/pl196x.zip.\n",
            "       | Downloading package porter_test to /root/nltk_data...\n",
            "       |   Unzipping stemmers/porter_test.zip.\n",
            "       | Downloading package ppattach to /root/nltk_data...\n",
            "       |   Unzipping corpora/ppattach.zip.\n",
            "       | Downloading package problem_reports to /root/nltk_data...\n",
            "       |   Unzipping corpora/problem_reports.zip.\n",
            "       | Downloading package product_reviews_1 to /root/nltk_data...\n",
            "       |   Unzipping corpora/product_reviews_1.zip.\n",
            "       | Downloading package product_reviews_2 to /root/nltk_data...\n",
            "       |   Unzipping corpora/product_reviews_2.zip.\n",
            "       | Downloading package propbank to /root/nltk_data...\n",
            "       | Downloading package pros_cons to /root/nltk_data...\n",
            "       |   Unzipping corpora/pros_cons.zip.\n",
            "       | Downloading package ptb to /root/nltk_data...\n",
            "       |   Unzipping corpora/ptb.zip.\n",
            "       | Downloading package punkt to /root/nltk_data...\n",
            "       |   Unzipping tokenizers/punkt.zip.\n",
            "       | Downloading package qc to /root/nltk_data...\n",
            "       |   Unzipping corpora/qc.zip.\n",
            "       | Downloading package reuters to /root/nltk_data...\n",
            "       | Downloading package rslp to /root/nltk_data...\n",
            "       |   Unzipping stemmers/rslp.zip.\n",
            "       | Downloading package rte to /root/nltk_data...\n",
            "       |   Unzipping corpora/rte.zip.\n",
            "       | Downloading package sample_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/sample_grammars.zip.\n",
            "       | Downloading package semcor to /root/nltk_data...\n",
            "       | Downloading package senseval to /root/nltk_data...\n",
            "       |   Unzipping corpora/senseval.zip.\n",
            "       | Downloading package sentence_polarity to /root/nltk_data...\n",
            "       |   Unzipping corpora/sentence_polarity.zip.\n",
            "       | Downloading package sentiwordnet to /root/nltk_data...\n",
            "       |   Unzipping corpora/sentiwordnet.zip.\n",
            "       | Downloading package shakespeare to /root/nltk_data...\n",
            "       |   Unzipping corpora/shakespeare.zip.\n",
            "       | Downloading package sinica_treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/sinica_treebank.zip.\n",
            "       | Downloading package smultron to /root/nltk_data...\n",
            "       |   Unzipping corpora/smultron.zip.\n",
            "       | Downloading package snowball_data to /root/nltk_data...\n",
            "       | Downloading package spanish_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/spanish_grammars.zip.\n",
            "       | Downloading package state_union to /root/nltk_data...\n",
            "       |   Unzipping corpora/state_union.zip.\n",
            "       | Downloading package stopwords to /root/nltk_data...\n",
            "       |   Unzipping corpora/stopwords.zip.\n",
            "       | Downloading package subjectivity to /root/nltk_data...\n",
            "       |   Unzipping corpora/subjectivity.zip.\n",
            "       | Downloading package swadesh to /root/nltk_data...\n",
            "       |   Unzipping corpora/swadesh.zip.\n",
            "       | Downloading package switchboard to /root/nltk_data...\n",
            "       |   Unzipping corpora/switchboard.zip.\n",
            "       | Downloading package tagsets to /root/nltk_data...\n",
            "       |   Unzipping help/tagsets.zip.\n",
            "       | Downloading package timit to /root/nltk_data...\n",
            "       |   Unzipping corpora/timit.zip.\n",
            "       | Downloading package toolbox to /root/nltk_data...\n",
            "       |   Unzipping corpora/toolbox.zip.\n",
            "       | Downloading package treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/treebank.zip.\n",
            "       | Downloading package twitter_samples to /root/nltk_data...\n",
            "       |   Unzipping corpora/twitter_samples.zip.\n",
            "       | Downloading package udhr to /root/nltk_data...\n",
            "       |   Unzipping corpora/udhr.zip.\n",
            "       | Downloading package udhr2 to /root/nltk_data...\n",
            "       |   Unzipping corpora/udhr2.zip.\n",
            "       | Downloading package unicode_samples to /root/nltk_data...\n",
            "       |   Unzipping corpora/unicode_samples.zip.\n",
            "       | Downloading package universal_tagset to /root/nltk_data...\n",
            "       |   Unzipping taggers/universal_tagset.zip.\n",
            "       | Downloading package universal_treebanks_v20 to\n",
            "       |     /root/nltk_data...\n",
            "       | Downloading package vader_lexicon to /root/nltk_data...\n",
            "       | Downloading package verbnet to /root/nltk_data...\n",
            "       |   Unzipping corpora/verbnet.zip.\n",
            "       | Downloading package verbnet3 to /root/nltk_data...\n",
            "       |   Unzipping corpora/verbnet3.zip.\n",
            "       | Downloading package webtext to /root/nltk_data...\n",
            "       |   Unzipping corpora/webtext.zip.\n",
            "       | Downloading package wmt15_eval to /root/nltk_data...\n",
            "       |   Unzipping models/wmt15_eval.zip.\n",
            "       | Downloading package word2vec_sample to /root/nltk_data...\n",
            "       |   Unzipping models/word2vec_sample.zip.\n",
            "       | Downloading package wordnet to /root/nltk_data...\n",
            "       | Downloading package wordnet2021 to /root/nltk_data...\n",
            "       | Downloading package wordnet31 to /root/nltk_data...\n",
            "       | Downloading package wordnet_ic to /root/nltk_data...\n",
            "       |   Unzipping corpora/wordnet_ic.zip.\n",
            "       | Downloading package words to /root/nltk_data...\n",
            "       |   Unzipping corpora/words.zip.\n",
            "       | Downloading package ycoe to /root/nltk_data...\n",
            "       |   Unzipping corpora/ycoe.zip.\n",
            "       | \n",
            "     Done downloading collection all\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the Movie Review corpus\n",
        "from nltk.corpus import movie_reviews"
      ],
      "metadata": {
        "id": "QYh7nGOEIshC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating a list of documents**"
      ],
      "metadata": {
        "id": "PDqjdA0OKnqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an empty list for storing the documents\n",
        "documents = []\n",
        "\n",
        "# For each category in the movie_reviews corpus\n",
        "for category in movie_reviews.categories():\n",
        "\n",
        "  # for each file identifiers in the each category\n",
        "  for fileid in movie_reviews.fileids(category):\n",
        "    \n",
        "    # appending the file identifiers and cateories in a list. (the fileids and categories are stored in a set)\n",
        "    documents.append((list(movie_reviews.words(fileid)), category))"
      ],
      "metadata": {
        "id": "EpjZEVLOIutf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We will now comment out the shuffle function for the documents**"
      ],
      "metadata": {
        "id": "idKZLUvpYLkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the shuffle function of the random module to shuffle the elements of the documents list.\n",
        "# random.shuffle(documents)"
      ],
      "metadata": {
        "id": "KHtFAH7rIwVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating a list of all word tokens**"
      ],
      "metadata": {
        "id": "4Tl02EZEM_UY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's get all the word tokens of the movie_review corpus and stored it in a list (all_words)\n",
        "all_words_tokens = []\n",
        "for w in movie_reviews.words():\n",
        "    all_words_tokens.append(w.lower()) # lowring the words"
      ],
      "metadata": {
        "id": "rjmdzy6TI0il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Frequency Distribution of all the word tokens**"
      ],
      "metadata": {
        "id": "uoL9bZI_NBA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the frequency distribition of all the words\n",
        "all_words_freq = nltk.FreqDist(all_words_tokens)"
      ],
      "metadata": {
        "id": "jKiJ8eaoI6qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out the length of the all frequent words list\n",
        "print(len(all_words_freq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTwDj90LLJRz",
        "outputId": "0b0f4761-2e41-4c01-c290-5011ddbe5ef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_words_freq.most_common(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WG1uexfqna4E",
        "outputId": "694ae013-671c-443b-ff85-ce857535dd15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(',', 77717),\n",
              " ('the', 76529),\n",
              " ('.', 65876),\n",
              " ('a', 38106),\n",
              " ('and', 35576),\n",
              " ('of', 34123),\n",
              " ('to', 31937),\n",
              " (\"'\", 30585),\n",
              " ('is', 25195),\n",
              " ('in', 21822),\n",
              " ('s', 18513),\n",
              " ('\"', 17612),\n",
              " ('it', 16107),\n",
              " ('that', 15924),\n",
              " ('-', 15595)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Removing Stopwords and Punctuations**"
      ],
      "metadata": {
        "id": "O9QBIEquMI5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing stopwords and punctuations\n",
        "from nltk.corpus import stopwords\n",
        "import string               # for punctuations"
      ],
      "metadata": {
        "id": "hILK1XX_JkAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the English stopwords\n",
        "stopwords_eng = stopwords.words(\"english\")"
      ],
      "metadata": {
        "id": "fUld2b_YJmdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a function to remove stopwords and punctuations\n",
        "def remove_punc_stopwords(txt):\n",
        "    \"\"\"\n",
        "        1. First we will remove punctutations\n",
        "        2. Then, we will remove stopwords\n",
        "        3. Lastly, we will return the clean word tokens\n",
        "    \"\"\"\n",
        "    nopunc = [char for char in txt if char not in string.punctuation]\n",
        "    no_stops = [word for word in nopunc if word.lower() not in stopwords_eng]\n",
        "    return no_stops"
      ],
      "metadata": {
        "id": "vufSXGQaJqal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Running the function on all word tokens\n",
        "all_words_tokens_cleaned = remove_punc_stopwords(all_words_tokens)"
      ],
      "metadata": {
        "id": "cWPlLx7UJraj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see the lengths of the all word tokens list prior and after removing stopwords and punctuations\n",
        "print(\"Original len of all word tokens = \", len(all_words_tokens))\n",
        "print(\"After removal of stopwords and punctuations,  len of all word tokens = \", len(all_words_tokens_cleaned))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvgpwdKgJ851",
        "outputId": "d8d65f1f-9ce9-4629-f6f7-3c00bb3be9b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original len of all word tokens =  1583820\n",
            "After removal of stopwords and punctuations,  len of all word tokens =  710578\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Frequency Distribution of all the word tokens after removing punctuations and stopwords\n",
        "all_words_tokens_cleaned_freq = nltk.FreqDist(all_words_tokens_cleaned)"
      ],
      "metadata": {
        "id": "7lMDOUhvJ82I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's see the top 15 most common words \n",
        "all_words_tokens_cleaned_freq.most_common(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1vbX5McJ8xn",
        "outputId": "88347fa5-c1e8-4001-9ad0-5dd45654e629"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('film', 9517),\n",
              " ('one', 5852),\n",
              " ('movie', 5771),\n",
              " ('like', 3690),\n",
              " ('even', 2565),\n",
              " ('good', 2411),\n",
              " ('time', 2411),\n",
              " ('story', 2169),\n",
              " ('would', 2109),\n",
              " ('much', 2049),\n",
              " ('character', 2020),\n",
              " ('also', 1967),\n",
              " ('get', 1949),\n",
              " ('two', 1911),\n",
              " ('well', 1906)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's check the length of all freq words\n",
        "print(len(all_words_tokens_cleaned_freq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRm7VF_6J8rH",
        "outputId": "d9d760ff-b4de-4f09-cb72-7887281a627b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Most common words (2000 freq words)\n",
        "most_common_word_tokens = all_words_tokens_cleaned_freq.most_common(2000)\n",
        "\n",
        "# print top 10 most common words\n",
        "print(most_common_word_tokens[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbDYjtalJ8oS",
        "outputId": "e1879262-a9b1-40f6-b0af-eca8e4756616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('film', 9517), ('one', 5852), ('movie', 5771), ('like', 3690), ('even', 2565), ('good', 2411), ('time', 2411), ('story', 2169), ('would', 2109), ('much', 2049)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Least 10 freq words (botton 10 common words)\n",
        "print(most_common_word_tokens[1990:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3lLnZxKJ8lm",
        "outputId": "5b757bb6-f836-436f-bb05-1ab8e010e165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('remain', 64), ('anna', 64), ('moved', 64), ('asking', 64), ('genuinely', 64), ('rain', 64), ('path', 64), ('aware', 64), ('causes', 64), ('international', 64)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Since the elements of the most_common_word_tokens list are in the form of tuples, we need to extract the first element of each tuple to get the words as word features\n",
        "word_features = [token[0] for token in most_common_word_tokens]\n",
        "\n",
        "# Print out the top 10 word features\n",
        "print(word_features[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4L9W2Aa3LfKz",
        "outputId": "85979d3c-9471-4015-8cc6-95621297b65f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['film', 'one', 'movie', 'like', 'even', 'good', 'time', 'story', 'would', 'much']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the word_features list\n",
        "len(word_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vhfUlG1LfH8",
        "outputId": "0b52a3d9-c563-4b98-a58b-577d5cd19027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating a Feature Set**"
      ],
      "metadata": {
        "id": "sw9IVYcNLl-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a function to get the features (words) in a dictionary\n",
        "def doc_features(doc):\n",
        "    \n",
        "    # creating a set for all the unique words present in a document\n",
        "    doc_words = set(doc)\n",
        "    \n",
        "    # creating an empty features list\n",
        "    features = {}\n",
        "    \n",
        "    # Will iterate through all the words present in the word_features list\n",
        "    for word in word_features:\n",
        "        \n",
        "        # Get that word and see its presence in the document (will return a bollean value)\n",
        "        features[word] = (word in doc_words)\n",
        "    \n",
        "    return features"
      ],
      "metadata": {
        "id": "boR_Xr5ULfEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, we are going to create a feature set which will contain the word features of the review and its correspoding category\n",
        "feature_sets = [(doc_features(review), category) for (review, category) in documents]"
      ],
      "metadata": {
        "id": "zyg_ynFJLe-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out the first element of the feature set\n",
        "print(feature_sets[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFKjOZ3VMsSr",
        "outputId": "0485038c-f068-419e-84d1-11630c5131f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'film': True, 'one': True, 'movie': True, 'like': True, 'even': True, 'good': True, 'time': False, 'story': False, 'would': True, 'much': False, 'character': True, 'also': True, 'get': True, 'two': True, 'well': True, 'characters': True, 'first': False, '--': False, 'see': True, 'way': True, 'make': True, 'life': True, 'really': True, 'films': True, 'plot': True, 'little': True, 'people': True, 'could': False, 'scene': False, 'man': False, 'bad': True, 'never': False, 'best': False, 'new': True, 'scenes': True, 'many': False, 'director': True, 'know': True, 'movies': True, 'action': False, 'great': False, 'another': False, 'love': False, 'go': True, 'made': False, 'us': True, 'big': True, 'end': False, 'something': False, 'back': True, 'still': True, 'world': True, 'seems': True, 'work': False, 'makes': True, 'however': False, 'every': True, 'though': False, 'better': False, 'real': False, 'audience': True, 'enough': False, 'seen': False, 'take': False, 'around': False, 'going': True, 'year': False, 'performance': False, 'role': False, 'old': False, 'gets': False, 'may': False, 'things': True, 'think': False, 'years': True, 'last': False, 'comedy': False, 'funny': False, 'actually': True, 'long': False, 'look': True, 'almost': False, 'thing': False, 'fact': False, 'nothing': False, 'say': False, 'right': False, 'john': False, 'although': True, 'played': False, 'find': True, 'script': False, 'come': False, 'ever': True, 'cast': False, 'since': True, 'star': False, 'plays': False, 'young': False, 'show': False, 'comes': False, 'part': True, 'original': False, 'actors': True, 'screen': False, 'without': False, 'acting': False, 'three': False, 'day': False, 'point': True, 'lot': False, 'least': False, 'takes': False, 'guy': False, 'quite': False, 'away': True, 'family': False, 'effects': False, 'course': False, 'goes': False, 'minutes': True, 'interesting': False, 'might': True, 'far': False, 'high': False, 'rather': False, 'must': False, 'anything': False, 'place': False, 'set': False, 'yet': False, 'watch': True, 'making': True, 'wife': False, 'hard': False, 'always': True, 'fun': False, 'seem': True, 'special': False, 'bit': True, 'times': False, 'trying': True, 'hollywood': False, 'instead': False, 'give': True, 'want': True, 'picture': False, 'kind': True, 'american': True, 'job': False, 'sense': True, 'woman': False, 'home': False, 'series': False, 'actor': False, 'probably': False, 'help': False, 'half': True, 'along': False, 'men': False, 'everything': False, 'pretty': True, 'becomes': False, 'sure': True, 'black': False, 'together': False, 'dialogue': False, 'money': False, 'become': False, 'gives': False, 'given': True, 'looking': False, 'whole': False, 'watching': False, 'father': False, 'feel': False, 'everyone': False, 'music': True, 'wants': False, 'sex': False, 'less': False, 'done': False, 'horror': True, 'got': True, 'death': False, 'perhaps': False, 'city': False, 'next': False, 'especially': False, 'play': False, 'girl': False, 'mind': True, '10': True, 'moments': False, 'looks': False, 'completely': True, '2': True, 'reason': False, 'mother': False, 'whose': False, 'line': True, 'night': False, 'human': False, 'rest': False, 'performances': False, 'different': True, 'evil': False, 'small': False, 'james': False, 'simply': True, 'couple': False, 'put': False, 'let': False, 'anyone': False, 'ending': True, 'case': False, 'several': False, 'dead': True, 'michael': False, 'left': False, 'thought': False, 'school': False, 'shows': True, 'humor': False, 'true': False, 'lost': True, 'written': False, 'friend': False, 'entire': True, 'getting': False, 'town': False, 'turns': False, 'soon': False, 'someone': True, 'second': False, 'main': True, 'stars': False, 'found': False, 'use': False, 'problem': True, 'friends': False, 'tv': False, 'top': False, 'name': False, 'begins': False, 'called': False, 'based': False, 'comic': False, 'david': False, 'head': True, 'else': False, 'idea': True, 'either': False, 'wrong': False, 'unfortunately': False, 'later': False, 'final': True, 'hand': False, 'alien': False, 'house': False, 'group': False, 'full': False, 'used': False, 'tries': False, 'often': False, 'war': False, 'sequence': False, 'keep': False, 'turn': False, 'playing': True, 'boy': False, 'behind': False, 'named': False, 'certainly': False, 'live': False, 'believe': False, 'works': False, 'relationship': False, 'face': False, 'hour': False, 'run': False, 'style': False, 'said': False, 'despite': True, 'person': False, 'finally': False, 'shot': False, 'book': False, 'tell': False, 'maybe': False, 'nice': False, 'son': False, 'perfect': False, 'side': False, 'seeing': False, 'able': False, 'finds': False, 'children': False, 'days': False, 'past': False, 'summer': False, 'camera': False, 'including': False, 'mr': False, 'kids': True, 'lives': False, 'directed': False, 'moment': False, 'game': False, 'running': True, 'fight': False, 'supposed': False, 'video': True, 'car': False, 'matter': False, 'kevin': False, 'joe': False, 'lines': False, 'worth': False, 'daughter': False, 'earth': False, 'starts': True, 'need': True, 'entertaining': True, 'white': False, 'start': True, 'writer': False, 'dark': False, 'short': False, 'self': False, 'worst': False, 'nearly': False, 'opening': False, 'try': False, 'upon': False, 'care': False, 'early': False, 'violence': False, 'throughout': True, 'team': False, 'production': True, 'example': False, 'beautiful': False, 'title': False, 'exactly': False, 'jack': False, 'review': True, 'major': False, 'drama': False, 'problems': True, 'sequences': False, 'obvious': False, 'version': False, 'screenplay': False, 'known': False, 'killer': False, 'robert': False, 'disney': False, 'already': False, 'close': False, 'classic': False, 'others': True, 'hit': False, 'kill': False, 'deep': False, 'five': True, 'order': False, 'act': False, 'simple': False, 'fine': False, 'heart': False, 'roles': False, 'jackie': False, 'direction': False, 'eyes': False, 'four': False, 'question': False, 'sort': False, 'sometimes': False, 'knows': False, 'supporting': False, 'coming': True, 'voice': False, 'women': False, 'truly': False, 'save': False, 'jokes': False, 'computer': False, 'child': False, 'boring': False, 'tom': False, 'level': False, '1': False, 'body': False, 'guys': True, 'genre': True, 'brother': False, 'strong': False, 'stop': False, 'room': False, 'space': False, 'lee': False, 'ends': False, 'beginning': False, 'ship': False, 'york': False, 'attempt': True, 'thriller': False, 'scream': False, 'peter': False, 'husband': False, 'fiction': False, 'happens': False, 'hero': False, 'novel': False, 'note': False, 'hope': False, 'king': False, 'yes': False, 'says': False, 'tells': False, 'quickly': False, 'romantic': False, 'dog': False, 'oscar': False, 'stupid': False, 'possible': False, 'saw': False, 'lead': False, 'career': False, 'murder': False, 'extremely': False, 'manages': False, 'god': False, 'mostly': False, 'wonder': False, 'particularly': False, 'future': False, 'fans': False, 'sound': False, 'worse': False, 'piece': False, 'involving': False, 'de': False, 'appears': False, 'planet': False, 'paul': False, 'involved': False, 'mean': True, 'none': False, 'taking': False, 'hours': False, 'laugh': False, 'police': False, 'sets': False, 'attention': False, 'co': False, 'hell': False, 'eventually': False, 'single': False, 'fall': False, 'falls': False, 'material': False, 'emotional': False, 'power': False, 'late': False, 'lack': False, 'dr': False, 'van': False, 'result': False, 'elements': False, 'meet': False, 'smith': False, 'science': False, 'experience': False, 'bring': False, 'wild': False, 'living': False, 'theater': False, 'interest': False, 'leads': False, 'word': False, 'feature': False, 'battle': False, 'girls': False, 'alone': False, 'obviously': True, 'george': False, 'within': False, 'usually': False, 'enjoy': False, 'guess': True, 'among': False, 'taken': True, 'feeling': True, 'laughs': False, 'aliens': False, 'talk': False, 'chance': False, 'talent': False, '3': True, 'middle': False, 'number': False, 'easy': False, 'across': False, 'needs': False, 'attempts': False, 'happen': True, 'television': False, 'chris': False, 'deal': True, 'poor': False, 'form': False, 'girlfriend': True, 'viewer': False, 'release': False, 'killed': False, 'forced': False, 'whether': False, 'wonderful': False, 'feels': True, 'oh': True, 'tale': False, 'serious': False, 'expect': False, 'except': False, 'light': False, 'success': False, 'features': False, 'premise': False, 'happy': False, 'words': False, 'leave': False, 'important': False, 'meets': False, 'history': False, 'giving': True, 'crew': False, 'type': False, 'call': False, 'turned': False, 'released': False, 'parents': False, 'art': False, 'impressive': False, 'mission': False, 'working': False, 'seemed': True, 'score': False, 'told': False, 'recent': False, 'robin': False, 'basically': False, 'entertainment': False, 'america': False, 'surprise': False, 'apparently': True, 'easily': False, 'ryan': False, 'cool': True, 'stuff': False, 'cop': False, 'change': False, 'williams': False, 'crime': False, 'office': False, 'parts': False, 'somehow': False, 'sequel': False, 'william': False, 'cut': False, 'die': False, 'jones': False, 'credits': False, 'batman': False, 'suspense': False, 'brings': False, 'events': False, 'reality': False, 'local': False, 'talking': False, 'difficult': False, 'using': False, 'went': False, 'writing': False, 'remember': False, 'near': False, 'straight': False, 'hilarious': False, 'ago': True, 'certain': False, 'ben': False, 'kid': False, 'slow': False, 'blood': False, 'mystery': False, 'complete': False, 'red': False, 'popular': False, 'effective': False, 'fast': False, 'flick': True, 'due': False, 'runs': False, 'gone': False, 'return': False, 'presence': False, 'quality': False, 'dramatic': False, 'filmmakers': False, 'age': False, 'brothers': False, 'business': False, 'general': False, 'rock': False, 'sexual': False, 'present': False, 'surprisingly': False, 'anyway': False, 'uses': False, '4': True, 'personal': False, 'figure': False, 'smart': False, 'ways': True, 'decides': False, 'annoying': False, 'begin': False, 'somewhat': False, 'shots': False, 'rich': False, 'minute': False, 'law': False, 'previous': False, 'jim': False, 'successful': False, 'harry': False, 'water': False, 'similar': False, 'absolutely': False, 'motion': False, 'former': False, 'strange': True, 'came': True, 'follow': False, 'read': False, 'project': False, 'million': False, 'secret': True, 'starring': False, 'clear': False, 'familiar': False, 'romance': False, 'intelligent': False, 'third': False, 'excellent': False, 'amazing': False, 'party': True, 'budget': False, 'eye': False, 'actress': False, 'prison': False, 'latest': False, 'means': False, 'company': False, 'towards': False, 'predictable': False, 'powerful': False, 'bob': False, 'beyond': False, 'visual': False, 'leaves': False, 'r': False, 'nature': False, 'following': False, 'villain': False, 'leaving': False, 'animated': False, 'low': False, 'b': False, 'bill': False, 'sam': False, 'filled': False, 'wars': False, 'questions': False, 'cinema': False, 'message': False, 'box': False, 'moving': False, 'country': False, 'usual': False, 'martin': False, 'definitely': False, 'add': False, 'large': False, 'clever': False, 'create': False, 'felt': False, 'stories': False, 'brilliant': False, 'ones': False, 'giant': False, 'situation': False, 'murphy': False, 'break': True, 'opens': False, 'scary': False, 'doubt': False, 'drug': False, 'bunch': False, 'thinking': False, 'solid': False, 'effect': False, 'learn': False, 'move': False, 'force': False, 'potential': False, 'seriously': False, 'follows': False, 'saying': False, 'huge': False, 'class': False, 'plan': False, 'agent': False, 'created': False, 'unlike': False, 'pay': False, 'non': False, 'married': False, 'mark': False, 'sweet': False, 'perfectly': False, 'ex': False, 'realize': False, 'audiences': False, 'took': True, 'decent': True, 'likely': False, 'dream': False, 'view': False, 'scott': False, 'subject': False, 'understand': False, 'happened': False, 'enjoyable': False, 'studio': True, 'immediately': False, 'open': False, 'e': False, 'points': False, 'heard': False, 'viewers': False, 'cameron': False, 'truman': False, 'bruce': False, 'frank': False, 'private': False, 'stay': False, 'fails': False, 'impossible': False, 'cold': False, 'richard': False, 'overall': True, 'merely': False, 'exciting': False, 'mess': True, 'chase': True, 'free': False, 'ten': False, 'neither': False, 'wanted': False, 'gun': False, 'appear': False, 'carter': False, 'escape': False, 'ultimately': False, 'fan': False, 'inside': False, 'favorite': False, 'modern': False, 'l': False, 'wedding': False, 'stone': False, 'trek': False, 'brought': False, 'trouble': False, 'otherwise': False, 'tim': False, '5': False, 'allen': False, 'bond': False, 'society': False, 'liked': False, 'dumb': False, 'musical': False, 'stand': False, 'political': False, 'various': False, 'talented': False, 'particular': False, 'west': False, 'state': False, 'keeps': False, 'english': False, 'silly': False, 'u': False, 'situations': False, 'park': False, 'teen': True, 'rating': False, 'slightly': False, 'steve': False, 'truth': False, 'air': False, 'element': False, 'joke': False, 'spend': False, 'key': False, 'biggest': True, 'members': False, 'effort': False, 'government': False, 'focus': False, 'eddie': False, 'soundtrack': False, 'hands': False, 'earlier': False, 'chan': False, 'purpose': False, 'today': False, 'showing': True, 'memorable': False, 'six': False, 'cannot': False, 'max': False, 'offers': False, 'rated': False, 'mars': False, 'heavy': False, 'totally': False, 'control': False, 'credit': False, 'fi': False, 'woody': False, 'ideas': False, 'sci': False, 'wait': False, 'sit': False, 'female': False, 'ask': False, 'waste': False, 'terrible': False, 'depth': False, 'simon': False, 'aspect': False, 'list': False, 'mary': False, 'sister': False, 'animation': False, 'entirely': False, 'fear': False, 'steven': False, 'moves': False, 'actual': False, 'army': False, 'british': False, 'constantly': False, 'fire': False, 'convincing': False, 'setting': False, 'gave': False, 'tension': False, 'street': True, '8': True, 'brief': False, 'ridiculous': False, 'cinematography': False, 'typical': False, 'nick': False, 'screenwriter': False, 'ability': False, 'spent': False, 'quick': False, 'violent': False, 'atmosphere': False, 'subtle': False, 'expected': False, 'fairly': False, 'seven': False, 'killing': False, 'tone': False, 'master': False, 'disaster': False, 'lots': False, 'thinks': False, 'song': False, 'cheap': False, 'suddenly': False, 'background': False, 'club': False, 'willis': False, 'whatever': True, 'highly': False, 'sees': False, 'complex': False, 'greatest': False, 'impact': False, 'beauty': True, 'front': False, 'humans': False, 'indeed': False, 'flat': False, 'grace': False, 'wrote': False, 'amusing': False, 'ii': False, 'mike': False, 'cute': False, 'dull': False, 'minor': False, 'recently': False, 'hate': False, 'outside': False, 'plenty': False, 'wish': False, 'godzilla': False, 'college': False, 'titanic': False, 'sounds': False, 'telling': False, 'sight': False, 'double': False, 'cinematic': False, 'queen': False, 'hold': False, 'meanwhile': False, 'awful': False, 'clearly': False, 'theme': False, 'hear': False, 'x': False, 'amount': False, 'baby': False, 'approach': False, 'dreams': True, 'shown': False, 'island': False, 'reasons': False, 'charm': False, 'miss': False, 'longer': False, 'common': False, 'sean': False, 'carry': False, 'believable': False, 'realistic': False, 'chemistry': False, 'possibly': False, 'casting': False, 'carrey': False, 'french': False, 'trailer': False, 'tough': False, 'produced': False, 'imagine': False, 'choice': False, 'ride': False, 'somewhere': True, 'hot': True, 'race': False, 'road': False, 'leader': False, 'thin': False, 'jerry': False, 'slowly': False, 'delivers': False, 'detective': False, 'brown': False, 'jackson': False, 'member': True, 'provide': False, 'president': False, 'puts': False, 'asks': False, 'critics': False, 'appearance': False, 'famous': False, 'okay': True, 'intelligence': False, 'energy': False, 'sent': False, 'spielberg': False, 'development': False, 'etc': False, 'language': False, 'blue': False, 'proves': False, 'vampire': False, 'seemingly': False, 'basic': False, 'caught': False, 'decide': False, 'opportunity': False, 'incredibly': False, 'images': False, 'band': False, 'j': False, 'writers': False, 'knew': False, 'interested': False, 'considering': False, 'boys': False, 'thanks': False, 'remains': False, 'climax': False, 'event': False, 'directing': False, 'conclusion': False, 'leading': False, 'ground': False, 'lies': False, 'forget': False, 'alive': False, 'tarzan': False, 'century': False, 'provides': False, 'trip': False, 'partner': False, 'central': False, 'tarantino': False, 'period': False, 'pace': False, 'worked': False, 'ready': False, 'date': False, 'thus': False, '1998': False, 'terrific': False, 'write': True, 'average': False, 'onto': False, 'songs': False, 'occasionally': False, 'doctor': False, 'stands': False, 'hardly': False, 'monster': False, 'led': False, 'mysterious': False, 'details': False, 'wasted': False, 'apart': False, 'aside': False, 'store': False, 'billy': False, 'boss': False, 'travolta': False, 'producer': False, 'pull': False, 'consider': False, 'pictures': False, 'becoming': False, 'cage': False, 'loud': False, 'looked': False, 'officer': False, 'twenty': False, 'system': False, 'contains': False, 'julia': False, 'subplot': False, 'missing': False, 'personality': False, 'building': False, 'learns': False, 'hong': False, 'la': False, 'apartment': False, '7': True, 'bizarre': False, 'powers': False, 'flaws': False, 'catch': False, 'lawyer': False, 'shoot': False, 'student': False, 'unique': False, '000': False, 'admit': False, 'concept': True, 'needed': False, 'thrown': False, 'christopher': False, 'laughing': False, 'green': False, 'twists': False, 'matthew': False, 'touch': False, 'waiting': False, 'victim': False, 'cover': False, 'machine': False, 'danny': False, 'mention': False, 'search': False, '1997': False, 'win': False, 'door': False, 'manner': False, 'train': False, 'saving': False, 'share': False, 'image': False, 'discovers': False, 'normal': True, 'cross': False, 'fox': False, 'returns': False, 'adult': False, 'adds': False, 'answer': False, 'adventure': False, 'lame': False, 'male': False, 'odd': False, 'singer': False, 'deserves': False, 'gore': False, 'states': False, 'include': False, 'equally': False, 'months': False, 'barely': False, 'directors': False, 'introduced': False, 'fashion': False, 'social': False, '1999': False, 'news': False, 'hair': False, 'dance': False, 'innocent': False, 'camp': False, 'teacher': False, 'became': False, 'sad': True, 'witch': True, 'includes': False, 'nights': False, 'jason': False, 'julie': False, 'latter': False, 'food': False, 'jennifer': False, 'land': False, 'menace': False, 'rate': False, 'storyline': False, 'contact': False, 'jean': False, 'elizabeth': False, 'fellow': False, 'changes': False, 'henry': False, 'hill': False, 'pulp': False, 'gay': False, 'tried': False, 'surprised': False, 'literally': False, 'walk': False, 'standard': False, '90': False, 'forward': False, 'wise': False, 'enjoyed': False, 'discover': False, 'pop': False, 'anderson': False, 'offer': False, 'recommend': False, 'public': False, 'drive': True, 'c': False, 'toy': False, 'charming': False, 'fair': False, 'chinese': False, 'rescue': False, 'terms': False, 'mouth': False, 'lucas': False, 'accident': True, 'dies': True, 'decided': True, 'edge': True, 'footage': False, 'culture': False, 'weak': False, 'presented': False, 'blade': False, 'younger': False, 'douglas': False, 'natural': False, 'born': False, 'generally': True, 'teenage': False, 'older': False, 'horrible': False, 'addition': False, 'sadly': False, 'creates': False, 'disturbing': False, 'roger': False, 'detail': False, 'devil': False, 'debut': False, 'track': False, 'developed': False, 'week': False, 'russell': False, 'attack': False, 'explain': False, 'rarely': True, 'fully': False, 'prove': False, 'exception': False, 'jeff': False, 'twist': False, 'gang': False, 'winning': False, 'jr': False, 'species': False, 'issues': False, 'fresh': False, 'rules': False, 'meaning': False, 'inspired': False, 'heroes': False, 'desperate': False, 'fighting': False, 'filmed': False, 'faces': False, 'alan': False, 'bright': False, 'ass': False, 'flying': False, 'kong': False, 'rush': False, 'forces': False, 'charles': False, 'numerous': False, 'emotions': False, 'involves': False, 'patrick': False, 'weird': True, 'apparent': False, 'information': False, 'revenge': False, 'jay': False, 'toward': False, 'surprising': False, 'twice': False, 'editing': False, 'calls': False, 'lose': False, 'vegas': False, 'stage': False, 'intended': False, 'gags': False, 'opinion': False, 'likes': False, 'crazy': False, 'owner': False, 'places': False, 'pair': False, 'genuine': False, 'epic': False, 'speak': False, 'throw': False, 'appeal': False, 'gibson': False, 'captain': False, 'military': False, '20': True, 'blair': True, 'nowhere': False, 'length': False, 'nicely': False, 'cause': False, 'pass': False, 'episode': False, 'kiss': False, 'arnold': False, 'please': False, 'phone': False, 'filmmaking': False, 'formula': False, 'boyfriend': False, 'talents': False, 'creating': False, 'kelly': False, 'buy': False, 'wide': False, 'fantasy': True, 'mood': False, 'heads': False, 'pathetic': False, 'lacks': False, 'loved': False, 'asked': False, 'mrs': False, 'witty': False, 'shakespeare': False, 'mulan': False, 'generation': True, 'affair': False, 'pieces': False, 'task': False, 'rare': False, 'kept': False, 'cameo': False, 'fascinating': False, 'ed': False, 'fbi': False, 'burton': False, 'incredible': False, 'accent': False, 'artist': False, 'superior': False, 'academy': False, 'thomas': False, 'spirit': False, 'technical': False, 'confusing': True, 'poorly': False, 'target': False, 'lover': False, 'woo': False, 'mentioned': False, 'theaters': False, 'plane': False, 'confused': False, 'dennis': False, 'rob': False, 'appropriate': False, 'christmas': False, 'considered': False, 'legend': False, 'shame': False, 'soul': False, 'matt': False, 'campbell': False, 'process': False, 'bottom': True, 'sitting': True, 'brain': False, 'creepy': False, '13': False, 'forever': False, 'dude': False, 'crap': False, 'superb': False, 'speech': False, 'ice': False, 'journey': False, 'masterpiece': False, 'intriguing': False, 'names': False, 'pick': False, 'speaking': False, 'virtually': False, 'award': False, 'worthy': False, 'marriage': False, 'deliver': False, 'cash': False, 'magic': False, 'respect': False, 'product': False, 'necessary': False, 'suppose': False, 'silent': False, 'pointless': False, 'station': False, 'affleck': False, 'dimensional': False, 'charlie': False, 'allows': False, 'avoid': False, 'meant': False, 'cops': False, 'attitude': False, 'relationships': False, 'hits': False, 'stephen': False, 'spends': False, 'relief': False, 'physical': False, 'count': False, 'reviews': False, 'appreciate': False, 'cliches': False, 'holds': True, 'pure': False, 'plans': False, 'limited': False, 'failed': False, 'pain': False, 'impression': False, 'unless': False, 'sub': False, 'total': False, 'creature': False, 'viewing': False, 'loves': False, 'princess': False, 'kate': False, 'rising': False, 'woods': False, 'baldwin': False, 'angry': False, 'drawn': False, 'step': False, 'matrix': False, 'themes': False, 'satire': False, 'arts': False, 'remake': False, 'wall': False, 'moral': False, 'color': False, 'ray': False, 'stuck': False, 'touching': False, 'wit': False, 'tony': False, 'hanks': False, 'continues': True, 'damn': False, 'nobody': False, 'cartoon': False, 'keeping': False, 'realized': False, 'criminal': False, 'unfunny': False, 'comedic': False, 'martial': False, 'disappointing': False, 'anti': False, 'graphic': False, 'stunning': False, 'actions': False, 'floor': False, 'emotion': False, 'soldiers': False, 'edward': False, 'comedies': False, 'driver': False, 'expectations': False, 'added': False, 'mad': False, 'angels': False, 'shallow': False, 'suspect': False, 'humorous': False, 'phantom': False, 'appealing': False, 'device': False, 'design': False, 'industry': False, 'reach': False, 'fat': False, 'blame': False, 'united': False, 'sign': False, 'portrayal': False, 'rocky': False, 'finale': False, 'grand': False, 'opposite': False, 'hotel': False, 'match': False, 'damme': False, 'speed': False, 'ok': False, 'loving': False, 'field': False, 'larry': False, 'urban': False, 'troopers': False, 'compared': False, 'apes': False, 'rose': False, 'falling': False, 'era': False, 'loses': False, 'adults': False, 'managed': False, 'dad': False, 'therefore': False, 'pg': False, 'results': False, 'guns': False, 'radio': False, 'lady': False, 'manage': False, 'spice': False, 'naked': False, 'started': False, 'intense': False, 'humanity': False, 'wonderfully': False, 'slasher': True, 'bland': False, 'imagination': False, 'walking': False, 'willing': False, 'horse': False, 'rent': False, 'mix': False, 'generated': False, 'g': False, 'utterly': False, 'scientist': False, 'washington': False, 'notice': False, 'players': False, 'teenagers': False, 'moore': False, 'board': False, 'price': False, 'frightening': False, 'tommy': False, 'spectacular': False, 'bored': False, 'jane': False, 'join': False, 'producers': False, 'johnny': False, 'zero': False, 'vampires': False, 'adaptation': False, 'dollars': False, 'parody': False, 'documentary': False, 'dvd': False, 'wayne': False, 'post': False, 'exist': False, 'matters': False, 'chosen': False, 'mel': False, 'attractive': False, 'plain': True, 'trust': False, 'safe': False, 'reading': False, 'hoping': False, 'protagonist': False, 'feelings': False, 'fate': False, 'finding': False, 'feet': False, 'visuals': False, 'spawn': False, 'compelling': False, 'hall': False, 'sympathetic': False, 'featuring': False, 'difference': False, 'professional': False, 'drugs': False, 'ford': False, 'shooting': False, 'gold': False, 'patch': False, 'build': False, 'boat': False, 'cruise': False, 'honest': False, 'media': False, 'flicks': True, 'bug': False, 'bringing': False, 'dangerous': False, 'watched': False, 'grant': False, 'smile': False, 'plus': False, 'decision': False, 'visually': False, 'allow': False, 'starship': False, 'roberts': False, 'dying': False, 'portrayed': False, 'turning': True, 'believes': False, 'changed': False, 'shock': False, 'destroy': False, '30': False, 'crowd': False, 'broken': False, 'tired': False, 'fail': False, 'south': False, 'died': False, 'cult': False, 'fake': False, 'vincent': False, 'identity': False, 'sexy': False, 'hunt': False, 'jedi': False, 'flynt': False, 'alex': False, 'engaging': True, 'serve': False, 'snake': False, 'yeah': False, 'expecting': False, '100': False, 'decade': False, 'ups': False, 'constant': False, 'current': False, 'survive': False, 'jimmy': False, 'buddy': False, 'send': False, 'brooks': False, 'goofy': False, 'likable': False, 'humour': False, 'technology': False, 'files': False, 'babe': False, 'aspects': False, 'presents': True, 'kills': False, 'supposedly': False, 'eight': False, 'sandler': False, 'hospital': False, 'test': False, 'hidden': False, 'brian': False, 'books': False, 'promise': False, 'determined': False, 'professor': False, 'welcome': False, 'pleasure': False, 'succeeds': False, 'individual': False, 'annie': False, 'mob': False, 'ted': False, 'virus': False, 'content': False, 'gary': False, 'direct': False, 'contrived': False, 'carpenter': False, 'scale': False, 'sick': False, 'nasty': False, 'conflict': False, 'haunting': False, 'ghost': False, 'filmmaker': False, 'japanese': False, 'helps': False, 'fare': False, 'lucky': False, 'ultimate': False, 'window': False, 'support': False, 'goal': False, 'provided': False, 'genius': False, 'winner': False, 'taylor': False, 'fantastic': False, 'faith': False, 'lynch': False, 'fit': False, 'catherine': False, 'ms': False, 'paced': False, 'breaks': False, 'al': False, 'frame': False, 'travel': False, 'badly': False, 'available': False, 'cares': False, 'reeves': False, 'crash': False, 'driving': False, 'press': False, 'seagal': False, 'amy': False, '9': True, 'headed': False, 'instance': False, 'excuse': False, 'offensive': False, 'narrative': False, 'fault': False, 'bus': False, 'f': False, 'extreme': False, 'miller': False, 'guilty': False, 'grows': False, 'overly': False, 'liners': False, 'forgotten': False, 'ahead': False, 'accept': False, 'porn': False, 'directly': False, 'helen': False, 'began': False, 'lord': False, 'folks': True, 'mediocre': False, 'bar': False, 'surface': False, 'super': False, 'failure': False, '6': False, 'acted': False, 'quiet': False, 'laughable': False, 'sheer': False, 'security': False, 'emotionally': False, 'season': False, 'stuart': False, 'jail': False, 'deals': False, 'cheesy': False, 'court': False, 'beach': False, 'austin': False, 'model': False, 'outstanding': False, 'substance': False, 'nudity': False, 'slapstick': False, 'joan': False, 'reveal': False, 'placed': False, 'check': False, 'beast': False, 'hurt': False, 'bloody': False, 'acts': False, 'fame': False, 'meeting': False, 'nuclear': False, '1996': False, 'strength': False, 'center': False, 'funniest': False, 'standing': False, 'damon': False, 'clich': False, 'position': False, 'desire': False, 'driven': False, 'seat': False, 'stock': False, 'wondering': False, 'realizes': False, 'dealing': False, 'taste': False, 'routine': False, 'comparison': False, 'cinematographer': False, 'seconds': False, 'singing': False, 'gangster': False, 'responsible': False, 'football': False, 'remarkable': False, 'hunting': False, 'adams': False, 'fly': False, 'suspects': False, 'treat': False, 'hopes': False, 'heaven': False, 'myers': False, 'struggle': False, 'costumes': False, 'beat': False, 'happening': False, 'skills': False, 'ugly': False, 'figures': False, 'thoroughly': False, 'ill': False, 'surprises': False, 'player': False, 'rival': False, 'guard': False, 'anthony': False, 'strike': False, 'community': False, 'streets': False, 'hopkins': False, 'ended': False, 'originally': False, 'sarah': False, 'creative': False, 'characterization': False, 'thankfully': False, 'growing': False, 'sharp': False, 'williamson': False, 'eccentric': False, 'explained': True, 'hey': False, 'claire': False, 'steal': False, 'inevitable': False, 'joel': False, 'core': False, 'sorry': False, 'built': False, 'anne': False, 'breaking': False, 'villains': False, 'critic': False, 'lets': False, 'visit': False, 'followed': False, 'serial': False, 'value': False, 'missed': False, 'oliver': False, 'hollow': False, 'sea': False, 'animal': False, 'freeman': False, 'animals': False, 'crystal': False, 'sidney': False, 'lacking': False, 'students': False, 'continue': False, 'extra': False, 'scorsese': False, 'church': True, 'stick': True, 'explanation': True, 'hip': False, 'quest': False, 'mistake': False, 'jump': False, 'fights': False, 'cusack': False, 'included': False, 'draw': False, '15': False, 'games': False, '1995': False, 'judge': False, 'gotten': False, 'chief': False, 'derek': False, 'thirty': False, 'record': False, 'everybody': False, 'veteran': False, 'develop': False, 'knowledge': False, 'serves': False, 'boogie': False, 'arrives': False, 'clooney': False, 'enter': True, 'russian': False, 'obsessed': False, 'vision': False, 'screenwriters': False, 'luck': False, 'holes': False, 'religious': False, 'witness': False, 'flashbacks': False, 'heavily': False, 'frequently': False, 'capable': False, 'armageddon': False, 'pacing': False, 'rise': False, 'mainly': False, 'fill': False, 'barry': False, 'schwarzenegger': False, 'clean': False, 'previously': False, 'grow': False, 'keaton': False, 'empty': False, 'synopsis': False, 'victims': False, 'adam': False, 'bed': False, 'lawrence': False, 'stallone': False, 'hunter': False, 'memory': False, 'suit': False, 'bobby': False, 'tragedy': False, 'saved': False, 'spot': False, 'unexpected': False, 'encounter': False, 'hearted': False, 'bacon': False, 'disappointment': False, 'bigger': False, 'noir': False, 'nicholson': False, 'evidence': False, 'relatively': False, 'morning': False, 'andrew': False, 'range': False, 'numbers': False, 'walter': False, 'vehicle': False, 'pulled': False, 'describe': False, 'cliched': False, 'sky': False, 'efforts': False, 'logic': False, 'verhoeven': False, 'assistant': False, 'existence': False, 'worker': False, 'freedom': False, 'theatre': False, 'wood': False, 'warm': False, 'fish': False, 'ripley': False, 'mental': False, 'study': False, 'justice': False, 'cliche': False, 'foot': False, 'jonathan': False, 'grown': False, 'unnecessary': False, 'rip': False, 'learned': False, 'skin': False, 'talks': False, 'ball': False, 'alice': False, 'roll': False, 'weeks': False, 'jon': False, 'courtroom': False, 'positive': False, 'putting': False, 'connection': False, 'london': False, 'angel': False, 'contrast': False, 'exact': True, 'fifteen': False, 'eric': False, 'prince': False, 'bound': False, 'traditional': False, 'regular': False, 'eve': False, 'niro': False, 'las': False, 'remain': False, 'anna': False, 'moved': False, 'asking': False, 'genuinely': False, 'rain': False, 'path': False, 'aware': False, 'causes': False, 'international': False}, 'neg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Training**\n",
        "\n",
        "Now, we will create training and testing sets."
      ],
      "metadata": {
        "id": "wzcInCmlSxMi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive data example "
      ],
      "metadata": {
        "id": "QUjWDt1vaj_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training set and Testing set\n",
        "train_data = feature_sets[:1900]\n",
        "test_data = feature_sets[1900:]"
      ],
      "metadata": {
        "id": "sT3xbrqiMxO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of training set\n",
        "len(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAGGoSKUS5Nx",
        "outputId": "a1966d47-eea8-4265-a209-845ea8ce6160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1900"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of testing set\n",
        "len(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRxLyI7FS6-W",
        "outputId": "c6964a34-719e-4060-d977-a648083a1df0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(len(train_data)/2000, len(test_data)/2000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6jwXl-7S8_p",
        "outputId": "e8b48ea2-8380-4934-9f5d-1d88642532f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.95, 0.05)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Negative data example"
      ],
      "metadata": {
        "id": "hFW7ibyYxLRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training set and Testing set\n",
        "train_data1 = feature_sets[100:]\n",
        "test_data1 = feature_sets[:100]"
      ],
      "metadata": {
        "id": "jgV5UVOqxJYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of training set\n",
        "len(train_data1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsfMojlzxPyO",
        "outputId": "140cd7df-5c7a-4d3a-af63-614af7e04ad3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1900"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of testing set\n",
        "len(test_data1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "do9eB4KDxSce",
        "outputId": "014b3ef5-7f82-4f9b-cdf0-bbd62aeff32c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(len(train_data1)/2000, len(test_data1)/2000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFNHHS86yN3f",
        "outputId": "2840b141-4fdc-469a-839a-e4c41334b05c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.95, 0.05)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be using the **Naive Bayes Classifier** for our training."
      ],
      "metadata": {
        "id": "rnkA1fvbTAA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the NaiveBayesClassifier from nltk\n",
        "from nltk import NaiveBayesClassifier\n",
        "\n",
        "# Creating an instance of our classifier and training the model\n",
        "base_model = NaiveBayesClassifier.train(train_data)\n",
        "base_model1 = NaiveBayesClassifier.train(train_data1)"
      ],
      "metadata": {
        "id": "x85JoqCDS-Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing classify from nltk\n",
        "from nltk import classify\n",
        "\n",
        "# Calculating the accuracy of the base model \n",
        "accuracy_score = classify.accuracy(base_model, test_data)\n",
        "accuracy_score1 = classify.accuracy(base_model1, test_data1)\n",
        "print(\"Accuracy Score of Base Model (+ve data example): {}%\".format(100 * accuracy_score))\n",
        "print(\"Accuracy Score of Base Model1 (-ve data example): {}%\".format(100 * accuracy_score1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwxyrgQES-E7",
        "outputId": "147b92d7-7430-49e2-8ad8-e5ccfffc1a29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score of Base Model (+ve data example): 76.0%\n",
            "Accuracy Score of Base Model1 (-ve data example): 87.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing other classifiers**"
      ],
      "metadata": {
        "id": "UdlL_0L9Kytn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing scikit-learn module from NLTK (a wrapper for sklearn)\n",
        "from nltk.classify.scikitlearn import SklearnClassifier"
      ],
      "metadata": {
        "id": "RPGJVGBnTWsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets use some other types of Naive Bayes classifiers from sklearn\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
        "\n",
        "# Lets import some more classifiers\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC"
      ],
      "metadata": {
        "id": "oUctZnGu31m1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multinomial Naive Bayes classifier\n",
        "multinomial_nb_model = SklearnClassifier(MultinomialNB())\n",
        "multinomial_nb_model.train(train_data)\n",
        "\n",
        "multinomial_nb_model1 = SklearnClassifier(MultinomialNB())\n",
        "multinomial_nb_model1.train(train_data1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2w6iQG5v32tb",
        "outputId": "6dde8fb8-be3a-4b4d-f42d-a9f3d0bb564f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SklearnClassifier(MultinomialNB())>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bernoulli Naive Bayes classifier\n",
        "bernoulli_nb_model = SklearnClassifier(BernoulliNB())\n",
        "bernoulli_nb_model.train(train_data)\n",
        "\n",
        "bernoulli_nb_model1 = SklearnClassifier(BernoulliNB())\n",
        "bernoulli_nb_model1.train(train_data1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOuew33s32mk",
        "outputId": "9a337024-fd2c-48de-a045-6a96c32b7975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SklearnClassifier(BernoulliNB())>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression classifier\n",
        "logit_model = SklearnClassifier(LogisticRegression())\n",
        "logit_model.train(train_data)\n",
        "\n",
        "logit_model1 = SklearnClassifier(LogisticRegression())\n",
        "logit_model1.train(train_data1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTGxBfVR36sd",
        "outputId": "55997554-4880-47c1-f06f-c8fd4e88af41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SklearnClassifier(LogisticRegression())>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stochastic Gradient Descent classifier\n",
        "sgd_model = SklearnClassifier(SGDClassifier())\n",
        "sgd_model.train(train_data)\n",
        "\n",
        "sgd_model1 = SklearnClassifier(SGDClassifier())\n",
        "sgd_model1.train(train_data1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlekKPU532ju",
        "outputId": "b1009799-5f31-45f5-f4cd-e04392ed921f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SklearnClassifier(SGDClassifier())>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# C-Support Vector Classification classifier\n",
        "svc_model = SklearnClassifier(SVC())\n",
        "svc_model.train(train_data)\n",
        "\n",
        "svc_model1 = SklearnClassifier(SVC())\n",
        "svc_model1.train(train_data1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYnhSaHi32hM",
        "outputId": "21491dd5-b456-4c0f-d62f-7a7f48eba429"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SklearnClassifier(SVC())>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Nu-Support Vector Classification classifier\n",
        "nu_svc_model = SklearnClassifier(NuSVC())\n",
        "nu_svc_model.train(train_data)\n",
        "\n",
        "nu_svc_model1 = SklearnClassifier(NuSVC())\n",
        "nu_svc_model1.train(train_data1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8uvY15f32ZU",
        "outputId": "b98cd13c-f1b7-4206-8a54-d2fedace9c8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SklearnClassifier(NuSVC())>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy on Positive data example"
      ],
      "metadata": {
        "id": "yoitON6uy8ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy Score of Base Model : {}%\".format(100 * accuracy_score))\n",
        "print(\"MultinomialNB Model Accuracy Score: {}%\".format(100 * classify.accuracy(multinomial_nb_model, test_data)))\n",
        "print(\"BernoulliNB Model Accuracy Score: {}%\".format(100 * classify.accuracy(bernoulli_nb_model, test_data)))\n",
        "print(\"LogisticRegression Model Accuracy Score: {}%\".format(100 * classify.accuracy(logit_model, test_data)))\n",
        "print(\"SGDClassifier Model Accuracy Score: {}%\".format(100 * classify.accuracy(sgd_model, test_data)))\n",
        "print(\"SVC Model Accuracy Score: {}%\".format(100 * classify.accuracy(svc_model, test_data)))\n",
        "print(\"NuSVC Model Accuracy Score: {}%\".format(100 * classify.accuracy(nu_svc_model, test_data)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uwsfZ2Y32Wx",
        "outputId": "79fef523-3146-4745-f70c-c8203f96577a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score of Base Model : 76.0%\n",
            "MultinomialNB Model Accuracy Score: 80.0%\n",
            "BernoulliNB Model Accuracy Score: 76.0%\n",
            "LogisticRegression Model Accuracy Score: 83.0%\n",
            "SGDClassifier Model Accuracy Score: 86.0%\n",
            "SVC Model Accuracy Score: 86.0%\n",
            "NuSVC Model Accuracy Score: 85.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy on Negative data example"
      ],
      "metadata": {
        "id": "VJuY1cdXzBGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy Score of Base Model : {}%\".format(100 * accuracy_score1))\n",
        "print(\"MultinomialNB Model Accuracy Score: {}%\".format(100 * classify.accuracy(multinomial_nb_model1, test_data1)))\n",
        "print(\"BernoulliNB Model Accuracy Score: {}%\".format(100 * classify.accuracy(bernoulli_nb_model1, test_data1)))\n",
        "print(\"LogisticRegression Model Accuracy Score: {}%\".format(100 * classify.accuracy(logit_model1, test_data1)))\n",
        "print(\"SGDClassifier Model Accuracy Score: {}%\".format(100 * classify.accuracy(sgd_model1, test_data1)))\n",
        "print(\"SVC Model Accuracy Score: {}%\".format(100 * classify.accuracy(svc_model1, test_data1)))\n",
        "print(\"NuSVC Model Accuracy Score: {}%\".format(100 * classify.accuracy(nu_svc_model1, test_data1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haMSiKSgzExW",
        "outputId": "31ee0099-d46c-475f-a408-10b9c6dc9e00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score of Base Model : 87.0%\n",
            "MultinomialNB Model Accuracy Score: 85.0%\n",
            "BernoulliNB Model Accuracy Score: 87.0%\n",
            "LogisticRegression Model Accuracy Score: 76.0%\n",
            "SGDClassifier Model Accuracy Score: 73.0%\n",
            "SVC Model Accuracy Score: 82.0%\n",
            "NuSVC Model Accuracy Score: 83.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We will build our classifier class for combining different algorithms**"
      ],
      "metadata": {
        "id": "QrCNkeZC4I09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing ClassifierI from the NLTK library\n",
        "from nltk.classify import ClassifierI"
      ],
      "metadata": {
        "id": "nRjNHiUk32UI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing mode from the statistics module\n",
        "from statistics import mode"
      ],
      "metadata": {
        "id": "ZsfvKJ_m32Rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a class for voting classifier and inheriting from ClassifierI class\n",
        "class VotingClassifier(ClassifierI):\n",
        "\n",
        "  # Next we will assign the list of classifiers that are passed to our class to self._classifiers\n",
        "  def __init__(self, *classifiers):\n",
        "     self._classifiers = classifiers\n",
        "\n",
        "\n",
        "  # Creating our own classify method and we will name it 'classify' to invoke '.classify' later on\n",
        "  def classify(self, features):\n",
        "\n",
        "    # Creating a list for storing the votes\n",
        "    votes = []\n",
        "\n",
        "    # Will iterate through list of classifiers classify them on our feartures\n",
        "    # and get the votes and append them in the votes list\n",
        "    # and return the mode of votes (most popular vote)\n",
        "    for algos in self._classifiers:\n",
        "      v = algos.classify(features)\n",
        "      votes.append(v)\n",
        "    return mode(votes)\n",
        "\n",
        "  # Creating a confidence method for getting the confidence indicator\n",
        "  # We will tally the votes for and against the winning vote \n",
        "  def confidence(self, features):\n",
        "    votes = []\n",
        "    for algos in self._classifiers:\n",
        "      v = algos.classify(features)\n",
        "      votes.append(v)\n",
        "\n",
        "    # Get the choice votes i.e. count the popular votes\n",
        "    choice_votes = votes.count(mode(votes))\n",
        "    \n",
        "    # Get the confidence by dividing choice votes by total number of votes\n",
        "    # and then return the confidence\n",
        "    conf = choice_votes / len(votes)\n",
        "    return conf"
      ],
      "metadata": {
        "id": "9x62Dw1U32PS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use some of the above created models in the voting classifier."
      ],
      "metadata": {
        "id": "vtGdrZrPDjaw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive data example"
      ],
      "metadata": {
        "id": "8kKcM6kNzV4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will now use the voting classifier and get the performance\n",
        "# as combination of algorithms (+ve data example)\n",
        "voted_model = VotingClassifier(base_model,\n",
        "                               multinomial_nb_model,\n",
        "                               bernoulli_nb_model,\n",
        "                               logit_model,\n",
        "                               sgd_model,\n",
        "                               svc_model,\n",
        "                               nu_svc_model)"
      ],
      "metadata": {
        "id": "OqbMS2LO32Mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Negative data example"
      ],
      "metadata": {
        "id": "xiVfr3d8zbk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will now use the voting classifier and get the performance\n",
        "# as combination of algorithms (-ve data example)\n",
        "voted_model1 = VotingClassifier(base_model1,\n",
        "                               multinomial_nb_model1,\n",
        "                               bernoulli_nb_model1,\n",
        "                               logit_model1,\n",
        "                               sgd_model1,\n",
        "                               svc_model1,\n",
        "                               nu_svc_model1)"
      ],
      "metadata": {
        "id": "A_jVvDGzzeH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing out the voted model accuracy\n",
        "print(\"Voted Model Accuracy Score (+ve data example): {}%\".format(100 * classify.accuracy(voted_model, test_data)))\n",
        "print(\"Voted Model Accuracy Score (-ve data example): {}%\".format(100 * classify.accuracy(voted_model1, test_data1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBAdCtYg32KS",
        "outputId": "074e9b82-54c2-441a-ecdc-844b3b940da5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voted Model Accuracy Score (+ve data example): 84.0%\n",
            "Voted Model Accuracy Score (-ve data example): 85.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1ieTVXhiE8vp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}