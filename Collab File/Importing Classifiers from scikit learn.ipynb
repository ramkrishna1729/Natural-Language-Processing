{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Importing the required modules**"
      ],
      "metadata": {
        "id": "n3JVipfsIGOP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5FIGu0rIQG3"
      },
      "outputs": [],
      "source": [
        "# Importing the NLTK library and Random module\n",
        "import nltk\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading all the NLTK files\n",
        "nltk.download_shell()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2EHKLtzIpwo",
        "outputId": "315e3787-1a6e-4145-d014-202077c1bc04"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> all\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    Downloading collection 'all'\n",
            "       | \n",
            "       | Downloading package abc to /root/nltk_data...\n",
            "       |   Unzipping corpora/abc.zip.\n",
            "       | Downloading package alpino to /root/nltk_data...\n",
            "       |   Unzipping corpora/alpino.zip.\n",
            "       | Downloading package averaged_perceptron_tagger to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "       | Downloading package averaged_perceptron_tagger_ru to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping taggers/averaged_perceptron_tagger_ru.zip.\n",
            "       | Downloading package basque_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/basque_grammars.zip.\n",
            "       | Downloading package biocreative_ppi to /root/nltk_data...\n",
            "       |   Unzipping corpora/biocreative_ppi.zip.\n",
            "       | Downloading package bllip_wsj_no_aux to /root/nltk_data...\n",
            "       |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "       | Downloading package book_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/book_grammars.zip.\n",
            "       | Downloading package brown to /root/nltk_data...\n",
            "       |   Unzipping corpora/brown.zip.\n",
            "       | Downloading package brown_tei to /root/nltk_data...\n",
            "       |   Unzipping corpora/brown_tei.zip.\n",
            "       | Downloading package cess_cat to /root/nltk_data...\n",
            "       |   Unzipping corpora/cess_cat.zip.\n",
            "       | Downloading package cess_esp to /root/nltk_data...\n",
            "       |   Unzipping corpora/cess_esp.zip.\n",
            "       | Downloading package chat80 to /root/nltk_data...\n",
            "       |   Unzipping corpora/chat80.zip.\n",
            "       | Downloading package city_database to /root/nltk_data...\n",
            "       |   Unzipping corpora/city_database.zip.\n",
            "       | Downloading package cmudict to /root/nltk_data...\n",
            "       |   Unzipping corpora/cmudict.zip.\n",
            "       | Downloading package comparative_sentences to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping corpora/comparative_sentences.zip.\n",
            "       | Downloading package comtrans to /root/nltk_data...\n",
            "       | Downloading package conll2000 to /root/nltk_data...\n",
            "       |   Unzipping corpora/conll2000.zip.\n",
            "       | Downloading package conll2002 to /root/nltk_data...\n",
            "       |   Unzipping corpora/conll2002.zip.\n",
            "       | Downloading package conll2007 to /root/nltk_data...\n",
            "       | Downloading package crubadan to /root/nltk_data...\n",
            "       |   Unzipping corpora/crubadan.zip.\n",
            "       | Downloading package dependency_treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/dependency_treebank.zip.\n",
            "       | Downloading package dolch to /root/nltk_data...\n",
            "       |   Unzipping corpora/dolch.zip.\n",
            "       | Downloading package europarl_raw to /root/nltk_data...\n",
            "       |   Unzipping corpora/europarl_raw.zip.\n",
            "       | Downloading package extended_omw to /root/nltk_data...\n",
            "       | Downloading package floresta to /root/nltk_data...\n",
            "       |   Unzipping corpora/floresta.zip.\n",
            "       | Downloading package framenet_v15 to /root/nltk_data...\n",
            "       |   Unzipping corpora/framenet_v15.zip.\n",
            "       | Downloading package framenet_v17 to /root/nltk_data...\n",
            "       |   Unzipping corpora/framenet_v17.zip.\n",
            "       | Downloading package gazetteers to /root/nltk_data...\n",
            "       |   Unzipping corpora/gazetteers.zip.\n",
            "       | Downloading package genesis to /root/nltk_data...\n",
            "       |   Unzipping corpora/genesis.zip.\n",
            "       | Downloading package gutenberg to /root/nltk_data...\n",
            "       |   Unzipping corpora/gutenberg.zip.\n",
            "       | Downloading package ieer to /root/nltk_data...\n",
            "       |   Unzipping corpora/ieer.zip.\n",
            "       | Downloading package inaugural to /root/nltk_data...\n",
            "       |   Unzipping corpora/inaugural.zip.\n",
            "       | Downloading package indian to /root/nltk_data...\n",
            "       |   Unzipping corpora/indian.zip.\n",
            "       | Downloading package jeita to /root/nltk_data...\n",
            "       | Downloading package kimmo to /root/nltk_data...\n",
            "       |   Unzipping corpora/kimmo.zip.\n",
            "       | Downloading package knbc to /root/nltk_data...\n",
            "       | Downloading package large_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/large_grammars.zip.\n",
            "       | Downloading package lin_thesaurus to /root/nltk_data...\n",
            "       |   Unzipping corpora/lin_thesaurus.zip.\n",
            "       | Downloading package mac_morpho to /root/nltk_data...\n",
            "       |   Unzipping corpora/mac_morpho.zip.\n",
            "       | Downloading package machado to /root/nltk_data...\n",
            "       | Downloading package masc_tagged to /root/nltk_data...\n",
            "       | Downloading package maxent_ne_chunker to /root/nltk_data...\n",
            "       |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "       | Downloading package maxent_treebank_pos_tagger to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "       | Downloading package moses_sample to /root/nltk_data...\n",
            "       |   Unzipping models/moses_sample.zip.\n",
            "       | Downloading package movie_reviews to /root/nltk_data...\n",
            "       |   Unzipping corpora/movie_reviews.zip.\n",
            "       | Downloading package mte_teip5 to /root/nltk_data...\n",
            "       |   Unzipping corpora/mte_teip5.zip.\n",
            "       | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "       |   Unzipping misc/mwa_ppdb.zip.\n",
            "       | Downloading package names to /root/nltk_data...\n",
            "       |   Unzipping corpora/names.zip.\n",
            "       | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "       | Downloading package nonbreaking_prefixes to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "       | Downloading package nps_chat to /root/nltk_data...\n",
            "       |   Unzipping corpora/nps_chat.zip.\n",
            "       | Downloading package omw to /root/nltk_data...\n",
            "       | Downloading package omw-1.4 to /root/nltk_data...\n",
            "       | Downloading package opinion_lexicon to /root/nltk_data...\n",
            "       |   Unzipping corpora/opinion_lexicon.zip.\n",
            "       | Downloading package panlex_swadesh to /root/nltk_data...\n",
            "       | Downloading package paradigms to /root/nltk_data...\n",
            "       |   Unzipping corpora/paradigms.zip.\n",
            "       | Downloading package pe08 to /root/nltk_data...\n",
            "       |   Unzipping corpora/pe08.zip.\n",
            "       | Downloading package perluniprops to /root/nltk_data...\n",
            "       |   Unzipping misc/perluniprops.zip.\n",
            "       | Downloading package pil to /root/nltk_data...\n",
            "       |   Unzipping corpora/pil.zip.\n",
            "       | Downloading package pl196x to /root/nltk_data...\n",
            "       |   Unzipping corpora/pl196x.zip.\n",
            "       | Downloading package porter_test to /root/nltk_data...\n",
            "       |   Unzipping stemmers/porter_test.zip.\n",
            "       | Downloading package ppattach to /root/nltk_data...\n",
            "       |   Unzipping corpora/ppattach.zip.\n",
            "       | Downloading package problem_reports to /root/nltk_data...\n",
            "       |   Unzipping corpora/problem_reports.zip.\n",
            "       | Downloading package product_reviews_1 to /root/nltk_data...\n",
            "       |   Unzipping corpora/product_reviews_1.zip.\n",
            "       | Downloading package product_reviews_2 to /root/nltk_data...\n",
            "       |   Unzipping corpora/product_reviews_2.zip.\n",
            "       | Downloading package propbank to /root/nltk_data...\n",
            "       | Downloading package pros_cons to /root/nltk_data...\n",
            "       |   Unzipping corpora/pros_cons.zip.\n",
            "       | Downloading package ptb to /root/nltk_data...\n",
            "       |   Unzipping corpora/ptb.zip.\n",
            "       | Downloading package punkt to /root/nltk_data...\n",
            "       |   Unzipping tokenizers/punkt.zip.\n",
            "       | Downloading package qc to /root/nltk_data...\n",
            "       |   Unzipping corpora/qc.zip.\n",
            "       | Downloading package reuters to /root/nltk_data...\n",
            "       | Downloading package rslp to /root/nltk_data...\n",
            "       |   Unzipping stemmers/rslp.zip.\n",
            "       | Downloading package rte to /root/nltk_data...\n",
            "       |   Unzipping corpora/rte.zip.\n",
            "       | Downloading package sample_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/sample_grammars.zip.\n",
            "       | Downloading package semcor to /root/nltk_data...\n",
            "       | Downloading package senseval to /root/nltk_data...\n",
            "       |   Unzipping corpora/senseval.zip.\n",
            "       | Downloading package sentence_polarity to /root/nltk_data...\n",
            "       |   Unzipping corpora/sentence_polarity.zip.\n",
            "       | Downloading package sentiwordnet to /root/nltk_data...\n",
            "       |   Unzipping corpora/sentiwordnet.zip.\n",
            "       | Downloading package shakespeare to /root/nltk_data...\n",
            "       |   Unzipping corpora/shakespeare.zip.\n",
            "       | Downloading package sinica_treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/sinica_treebank.zip.\n",
            "       | Downloading package smultron to /root/nltk_data...\n",
            "       |   Unzipping corpora/smultron.zip.\n",
            "       | Downloading package snowball_data to /root/nltk_data...\n",
            "       | Downloading package spanish_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/spanish_grammars.zip.\n",
            "       | Downloading package state_union to /root/nltk_data...\n",
            "       |   Unzipping corpora/state_union.zip.\n",
            "       | Downloading package stopwords to /root/nltk_data...\n",
            "       |   Unzipping corpora/stopwords.zip.\n",
            "       | Downloading package subjectivity to /root/nltk_data...\n",
            "       |   Unzipping corpora/subjectivity.zip.\n",
            "       | Downloading package swadesh to /root/nltk_data...\n",
            "       |   Unzipping corpora/swadesh.zip.\n",
            "       | Downloading package switchboard to /root/nltk_data...\n",
            "       |   Unzipping corpora/switchboard.zip.\n",
            "       | Downloading package tagsets to /root/nltk_data...\n",
            "       |   Unzipping help/tagsets.zip.\n",
            "       | Downloading package timit to /root/nltk_data...\n",
            "       |   Unzipping corpora/timit.zip.\n",
            "       | Downloading package toolbox to /root/nltk_data...\n",
            "       |   Unzipping corpora/toolbox.zip.\n",
            "       | Downloading package treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/treebank.zip.\n",
            "       | Downloading package twitter_samples to /root/nltk_data...\n",
            "       |   Unzipping corpora/twitter_samples.zip.\n",
            "       | Downloading package udhr to /root/nltk_data...\n",
            "       |   Unzipping corpora/udhr.zip.\n",
            "       | Downloading package udhr2 to /root/nltk_data...\n",
            "       |   Unzipping corpora/udhr2.zip.\n",
            "       | Downloading package unicode_samples to /root/nltk_data...\n",
            "       |   Unzipping corpora/unicode_samples.zip.\n",
            "       | Downloading package universal_tagset to /root/nltk_data...\n",
            "       |   Unzipping taggers/universal_tagset.zip.\n",
            "       | Downloading package universal_treebanks_v20 to\n",
            "       |     /root/nltk_data...\n",
            "       | Downloading package vader_lexicon to /root/nltk_data...\n",
            "       | Downloading package verbnet to /root/nltk_data...\n",
            "       |   Unzipping corpora/verbnet.zip.\n",
            "       | Downloading package verbnet3 to /root/nltk_data...\n",
            "       |   Unzipping corpora/verbnet3.zip.\n",
            "       | Downloading package webtext to /root/nltk_data...\n",
            "       |   Unzipping corpora/webtext.zip.\n",
            "       | Downloading package wmt15_eval to /root/nltk_data...\n",
            "       |   Unzipping models/wmt15_eval.zip.\n",
            "       | Downloading package word2vec_sample to /root/nltk_data...\n",
            "       |   Unzipping models/word2vec_sample.zip.\n",
            "       | Downloading package wordnet to /root/nltk_data...\n",
            "       | Downloading package wordnet2021 to /root/nltk_data...\n",
            "       | Downloading package wordnet31 to /root/nltk_data...\n",
            "       | Downloading package wordnet_ic to /root/nltk_data...\n",
            "       |   Unzipping corpora/wordnet_ic.zip.\n",
            "       | Downloading package words to /root/nltk_data...\n",
            "       |   Unzipping corpora/words.zip.\n",
            "       | Downloading package ycoe to /root/nltk_data...\n",
            "       |   Unzipping corpora/ycoe.zip.\n",
            "       | \n",
            "     Done downloading collection all\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iuPDqa7SIEzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the Movie Review corpus\n",
        "from nltk.corpus import movie_reviews"
      ],
      "metadata": {
        "id": "QYh7nGOEIshC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating a list of documents**"
      ],
      "metadata": {
        "id": "9k4YhrDdIMaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an empty list for storing the documents\n",
        "documents = []\n",
        "\n",
        "# For each category in the movie_reviews corpus\n",
        "for category in movie_reviews.categories():\n",
        "\n",
        "  # for each file identifiers in the each category\n",
        "  for fileid in movie_reviews.fileids(category):\n",
        "    \n",
        "    # appending the file identifiers and cateories in a list. (the fileids and categories are stored in a set)\n",
        "    documents.append((list(movie_reviews.words(fileid)), category))"
      ],
      "metadata": {
        "id": "EpjZEVLOIutf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the shuffle function of the random module to shuffle the elements of the documents list.\n",
        "random.shuffle(documents)"
      ],
      "metadata": {
        "id": "KHtFAH7rIwVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating a list of all word tokens**"
      ],
      "metadata": {
        "id": "4Tl02EZEM_UY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's get all the word tokens of the movie_review corpus and stored it in a list (all_words)\n",
        "all_words_tokens = []\n",
        "for w in movie_reviews.words():\n",
        "    all_words_tokens.append(w.lower()) # lowring the words"
      ],
      "metadata": {
        "id": "rjmdzy6TI0il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Frequency Distribution of all the word tokens**"
      ],
      "metadata": {
        "id": "uoL9bZI_NBA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the frequency distribition of all the words\n",
        "all_words_freq = nltk.FreqDist(all_words_tokens)"
      ],
      "metadata": {
        "id": "jKiJ8eaoI6qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out the length of the all frequent words list\n",
        "print(len(all_words_freq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTwDj90LLJRz",
        "outputId": "fb6cad4c-4ba1-48e1-9c68-bfd5064f5073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_words_freq.most_common(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WG1uexfqna4E",
        "outputId": "a79a3440-f5b8-4cad-c80e-9c200377ae47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(',', 77717),\n",
              " ('the', 76529),\n",
              " ('.', 65876),\n",
              " ('a', 38106),\n",
              " ('and', 35576),\n",
              " ('of', 34123),\n",
              " ('to', 31937),\n",
              " (\"'\", 30585),\n",
              " ('is', 25195),\n",
              " ('in', 21822),\n",
              " ('s', 18513),\n",
              " ('\"', 17612),\n",
              " ('it', 16107),\n",
              " ('that', 15924),\n",
              " ('-', 15595)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Removing Stopwords and Punctuations**"
      ],
      "metadata": {
        "id": "O9QBIEquMI5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing stopwords and punctuations\n",
        "from nltk.corpus import stopwords\n",
        "import string               # for punctuations"
      ],
      "metadata": {
        "id": "hILK1XX_JkAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the English stopwords\n",
        "stopwords_eng = stopwords.words(\"english\")"
      ],
      "metadata": {
        "id": "fUld2b_YJmdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a function to remove stopwords and punctuations\n",
        "def remove_punc_stopwords(txt):\n",
        "    \"\"\"\n",
        "        1. First we will remove punctutations\n",
        "        2. Then, we will remove stopwords\n",
        "        3. Lastly, we will return the clean word tokens\n",
        "    \"\"\"\n",
        "    nopunc = [char for char in txt if char not in string.punctuation]\n",
        "    no_stops = [word for word in nopunc if word.lower() not in stopwords_eng]\n",
        "    return no_stops"
      ],
      "metadata": {
        "id": "vufSXGQaJqal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Running the function on all word tokens\n",
        "all_words_tokens_cleaned = remove_punc_stopwords(all_words_tokens)"
      ],
      "metadata": {
        "id": "cWPlLx7UJraj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see the lengths of the all word tokens list prior and after removing stopwords and punctuations\n",
        "print(\"Original len of all word tokens = \", len(all_words_tokens))\n",
        "print(\"After removal of stopwords and punctuations,  len of all word tokens = \", len(all_words_tokens_cleaned))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvgpwdKgJ851",
        "outputId": "96e25942-563f-47db-bf9f-799f231c340e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original len of all word tokens =  1583820\n",
            "After removal of stopwords and punctuations,  len of all word tokens =  710578\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Frequency Distribution of all the word tokens after removing punctuations and stopwords\n",
        "all_words_tokens_cleaned_freq = nltk.FreqDist(all_words_tokens_cleaned)"
      ],
      "metadata": {
        "id": "7lMDOUhvJ82I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's see the top 15 most common words \n",
        "all_words_tokens_cleaned_freq.most_common(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1vbX5McJ8xn",
        "outputId": "2a60f091-1a13-4bd1-db93-d6919877ea7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('film', 9517),\n",
              " ('one', 5852),\n",
              " ('movie', 5771),\n",
              " ('like', 3690),\n",
              " ('even', 2565),\n",
              " ('good', 2411),\n",
              " ('time', 2411),\n",
              " ('story', 2169),\n",
              " ('would', 2109),\n",
              " ('much', 2049),\n",
              " ('character', 2020),\n",
              " ('also', 1967),\n",
              " ('get', 1949),\n",
              " ('two', 1911),\n",
              " ('well', 1906)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's check the length of all freq words\n",
        "print(len(all_words_tokens_cleaned_freq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRm7VF_6J8rH",
        "outputId": "edbd9dde-97be-49f0-cf57-fdbd6e72a6bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Most common words (2000 freq words)\n",
        "most_common_word_tokens = all_words_tokens_cleaned_freq.most_common(2000)\n",
        "\n",
        "# print top 10 most common words\n",
        "print(most_common_word_tokens[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbDYjtalJ8oS",
        "outputId": "67e74b35-385c-49ba-b76e-764522a5c188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('film', 9517), ('one', 5852), ('movie', 5771), ('like', 3690), ('even', 2565), ('good', 2411), ('time', 2411), ('story', 2169), ('would', 2109), ('much', 2049)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Least 10 freq words (botton 10 common words)\n",
        "print(most_common_word_tokens[1990:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3lLnZxKJ8lm",
        "outputId": "94b24289-1524-4669-f0f6-8a2c7388ff0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('remain', 64), ('anna', 64), ('moved', 64), ('asking', 64), ('genuinely', 64), ('rain', 64), ('path', 64), ('aware', 64), ('causes', 64), ('international', 64)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Since the elements of the most_common_word_tokens list are in the form of tuples, \n",
        "# we need to extract the first element of each tuple to get the words as word features\n",
        "word_features = [token[0] for token in most_common_word_tokens]\n",
        "\n",
        "# Print out the top 10 word features\n",
        "print(word_features[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4L9W2Aa3LfKz",
        "outputId": "deee689d-ddbb-48a0-a3ec-4846235ae284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['film', 'one', 'movie', 'like', 'even', 'good', 'time', 'story', 'would', 'much']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the word_features list\n",
        "len(word_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vhfUlG1LfH8",
        "outputId": "a38992ad-1bd5-47f2-c658-8155bd41763d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating a Feature Set**"
      ],
      "metadata": {
        "id": "sw9IVYcNLl-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a function to get the features (words) in a dictionary\n",
        "def doc_features(doc):\n",
        "    \n",
        "    # creating a set for all the unique words present in a document\n",
        "    doc_words = set(doc)\n",
        "    \n",
        "    # creating an empty features list\n",
        "    features = {}\n",
        "    \n",
        "    # Will iterate through all the words present in the word_features list\n",
        "    for word in word_features:\n",
        "        \n",
        "        # Get that word and see its presence in the document (will return a bollean value)\n",
        "        features[word] = (word in doc_words)\n",
        "    \n",
        "    return features"
      ],
      "metadata": {
        "id": "boR_Xr5ULfEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, we are going to create a feature set which will contain the word features of the review and its correspoding category\n",
        "feature_sets = [(doc_features(review), category) for (review, category) in documents]"
      ],
      "metadata": {
        "id": "zyg_ynFJLe-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out the first element of the feature set\n",
        "print(feature_sets[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFKjOZ3VMsSr",
        "outputId": "8bba8327-5363-40a1-8f9c-a9411067b368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'film': True, 'one': True, 'movie': True, 'like': False, 'even': True, 'good': False, 'time': True, 'story': False, 'would': True, 'much': True, 'character': True, 'also': True, 'get': False, 'two': True, 'well': False, 'characters': True, 'first': True, '--': True, 'see': True, 'way': False, 'make': False, 'life': True, 'really': False, 'films': True, 'plot': False, 'little': True, 'people': False, 'could': False, 'scene': False, 'man': False, 'bad': False, 'never': False, 'best': True, 'new': False, 'scenes': True, 'many': False, 'director': True, 'know': False, 'movies': False, 'action': False, 'great': True, 'another': True, 'love': False, 'go': False, 'made': False, 'us': False, 'big': False, 'end': True, 'something': False, 'back': True, 'still': True, 'world': True, 'seems': False, 'work': False, 'makes': True, 'however': True, 'every': True, 'though': True, 'better': False, 'real': False, 'audience': True, 'enough': False, 'seen': False, 'take': True, 'around': False, 'going': False, 'year': True, 'performance': False, 'role': True, 'old': False, 'gets': False, 'may': False, 'things': False, 'think': False, 'years': False, 'last': False, 'comedy': False, 'funny': False, 'actually': False, 'long': False, 'look': False, 'almost': False, 'thing': True, 'fact': True, 'nothing': False, 'say': False, 'right': True, 'john': True, 'although': False, 'played': False, 'find': False, 'script': False, 'come': False, 'ever': False, 'cast': False, 'since': False, 'star': True, 'plays': False, 'young': True, 'show': False, 'comes': True, 'part': True, 'original': False, 'actors': True, 'screen': False, 'without': False, 'acting': False, 'three': True, 'day': False, 'point': False, 'lot': True, 'least': False, 'takes': False, 'guy': False, 'quite': True, 'away': False, 'family': True, 'effects': True, 'course': False, 'goes': True, 'minutes': False, 'interesting': True, 'might': False, 'far': True, 'high': True, 'rather': False, 'must': False, 'anything': True, 'place': True, 'set': False, 'yet': True, 'watch': False, 'making': False, 'wife': False, 'hard': False, 'always': True, 'fun': False, 'seem': False, 'special': False, 'bit': True, 'times': True, 'trying': True, 'hollywood': False, 'instead': False, 'give': False, 'want': False, 'picture': False, 'kind': False, 'american': False, 'job': False, 'sense': True, 'woman': False, 'home': False, 'series': False, 'actor': False, 'probably': False, 'help': False, 'half': False, 'along': False, 'men': False, 'everything': False, 'pretty': False, 'becomes': True, 'sure': False, 'black': False, 'together': False, 'dialogue': False, 'money': False, 'become': False, 'gives': False, 'given': True, 'looking': False, 'whole': True, 'watching': False, 'father': False, 'feel': True, 'everyone': False, 'music': False, 'wants': False, 'sex': False, 'less': False, 'done': False, 'horror': False, 'got': False, 'death': False, 'perhaps': True, 'city': False, 'next': True, 'especially': True, 'play': True, 'girl': False, 'mind': False, '10': False, 'moments': False, 'looks': False, 'completely': True, '2': False, 'reason': False, 'mother': False, 'whose': True, 'line': False, 'night': False, 'human': False, 'rest': False, 'performances': False, 'different': True, 'evil': False, 'small': False, 'james': True, 'simply': False, 'couple': False, 'put': False, 'let': False, 'anyone': False, 'ending': False, 'case': False, 'several': False, 'dead': False, 'michael': True, 'left': False, 'thought': True, 'school': False, 'shows': False, 'humor': False, 'true': False, 'lost': False, 'written': False, 'friend': False, 'entire': True, 'getting': False, 'town': False, 'turns': False, 'soon': False, 'someone': False, 'second': False, 'main': True, 'stars': True, 'found': False, 'use': True, 'problem': False, 'friends': False, 'tv': False, 'top': True, 'name': False, 'begins': False, 'called': False, 'based': False, 'comic': False, 'david': True, 'head': False, 'else': True, 'idea': False, 'either': False, 'wrong': True, 'unfortunately': False, 'later': False, 'final': False, 'hand': False, 'alien': True, 'house': True, 'group': False, 'full': False, 'used': False, 'tries': False, 'often': False, 'war': False, 'sequence': False, 'keep': False, 'turn': False, 'playing': False, 'boy': False, 'behind': False, 'named': False, 'certainly': False, 'live': False, 'believe': False, 'works': False, 'relationship': False, 'face': False, 'hour': True, 'run': False, 'style': False, 'said': False, 'despite': False, 'person': False, 'finally': False, 'shot': False, 'book': False, 'tell': False, 'maybe': False, 'nice': False, 'son': False, 'perfect': False, 'side': True, 'seeing': False, 'able': False, 'finds': False, 'children': False, 'days': False, 'past': False, 'summer': True, 'camera': False, 'including': False, 'mr': False, 'kids': False, 'lives': False, 'directed': False, 'moment': True, 'game': False, 'running': False, 'fight': False, 'supposed': False, 'video': False, 'car': False, 'matter': False, 'kevin': False, 'joe': False, 'lines': False, 'worth': False, 'daughter': False, 'earth': True, 'starts': False, 'need': False, 'entertaining': True, 'white': True, 'start': False, 'writer': False, 'dark': False, 'short': False, 'self': False, 'worst': False, 'nearly': False, 'opening': False, 'try': False, 'upon': True, 'care': False, 'early': False, 'violence': False, 'throughout': False, 'team': False, 'production': False, 'example': False, 'beautiful': False, 'title': False, 'exactly': False, 'jack': False, 'review': False, 'major': False, 'drama': True, 'problems': False, 'sequences': False, 'obvious': False, 'version': False, 'screenplay': False, 'known': True, 'killer': False, 'robert': True, 'disney': False, 'already': False, 'close': True, 'classic': False, 'others': True, 'hit': False, 'kill': False, 'deep': False, 'five': False, 'order': False, 'act': False, 'simple': False, 'fine': False, 'heart': True, 'roles': True, 'jackie': False, 'direction': False, 'eyes': False, 'four': False, 'question': False, 'sort': False, 'sometimes': False, 'knows': False, 'supporting': False, 'coming': False, 'voice': False, 'women': False, 'truly': False, 'save': False, 'jokes': False, 'computer': False, 'child': False, 'boring': False, 'tom': True, 'level': False, '1': False, 'body': False, 'guys': False, 'genre': False, 'brother': False, 'strong': False, 'stop': False, 'room': False, 'space': True, 'lee': False, 'ends': False, 'beginning': False, 'ship': False, 'york': False, 'attempt': False, 'thriller': False, 'scream': False, 'peter': False, 'husband': False, 'fiction': True, 'happens': False, 'hero': False, 'novel': True, 'note': False, 'hope': False, 'king': False, 'yes': False, 'says': True, 'tells': False, 'quickly': False, 'romantic': False, 'dog': False, 'oscar': True, 'stupid': False, 'possible': False, 'saw': False, 'lead': False, 'career': False, 'murder': False, 'extremely': False, 'manages': False, 'god': False, 'mostly': False, 'wonder': True, 'particularly': False, 'future': False, 'fans': False, 'sound': True, 'worse': False, 'piece': False, 'involving': False, 'de': False, 'appears': False, 'planet': False, 'paul': False, 'involved': False, 'mean': True, 'none': False, 'taking': False, 'hours': False, 'laugh': False, 'police': False, 'sets': False, 'attention': False, 'co': False, 'hell': False, 'eventually': False, 'single': True, 'fall': False, 'falls': False, 'material': False, 'emotional': True, 'power': True, 'late': True, 'lack': False, 'dr': True, 'van': False, 'result': False, 'elements': False, 'meet': False, 'smith': False, 'science': True, 'experience': False, 'bring': False, 'wild': False, 'living': False, 'theater': False, 'interest': False, 'leads': False, 'word': False, 'feature': False, 'battle': False, 'girls': False, 'alone': False, 'obviously': False, 'george': False, 'within': False, 'usually': False, 'enjoy': False, 'guess': False, 'among': False, 'taken': False, 'feeling': False, 'laughs': False, 'aliens': False, 'talk': False, 'chance': True, 'talent': False, '3': False, 'middle': False, 'number': False, 'easy': True, 'across': True, 'needs': False, 'attempts': False, 'happen': False, 'television': False, 'chris': False, 'deal': False, 'poor': False, 'form': False, 'girlfriend': False, 'viewer': False, 'release': False, 'killed': False, 'forced': False, 'whether': False, 'wonderful': False, 'feels': False, 'oh': False, 'tale': False, 'serious': False, 'expect': False, 'except': False, 'light': False, 'success': False, 'features': False, 'premise': False, 'happy': False, 'words': False, 'leave': False, 'important': False, 'meets': False, 'history': False, 'giving': True, 'crew': False, 'type': False, 'call': False, 'turned': False, 'released': False, 'parents': False, 'art': False, 'impressive': False, 'mission': False, 'working': False, 'seemed': False, 'score': False, 'told': False, 'recent': False, 'robin': False, 'basically': False, 'entertainment': True, 'america': False, 'surprise': True, 'apparently': False, 'easily': False, 'ryan': False, 'cool': False, 'stuff': False, 'cop': False, 'change': True, 'williams': False, 'crime': False, 'office': False, 'parts': False, 'somehow': False, 'sequel': False, 'william': False, 'cut': False, 'die': False, 'jones': False, 'credits': False, 'batman': False, 'suspense': True, 'brings': False, 'events': False, 'reality': False, 'local': False, 'talking': False, 'difficult': False, 'using': False, 'went': False, 'writing': True, 'remember': False, 'near': False, 'straight': False, 'hilarious': False, 'ago': False, 'certain': False, 'ben': False, 'kid': False, 'slow': False, 'blood': False, 'mystery': False, 'complete': False, 'red': False, 'popular': False, 'effective': False, 'fast': False, 'flick': False, 'due': False, 'runs': False, 'gone': False, 'return': False, 'presence': False, 'quality': False, 'dramatic': False, 'filmmakers': False, 'age': False, 'brothers': False, 'business': False, 'general': False, 'rock': False, 'sexual': False, 'present': False, 'surprisingly': False, 'anyway': False, 'uses': False, '4': False, 'personal': False, 'figure': False, 'smart': True, 'ways': False, 'decides': False, 'annoying': False, 'begin': False, 'somewhat': False, 'shots': False, 'rich': False, 'minute': False, 'law': False, 'previous': False, 'jim': False, 'successful': False, 'harry': False, 'water': False, 'similar': False, 'absolutely': False, 'motion': False, 'former': False, 'strange': False, 'came': False, 'follow': False, 'read': False, 'project': False, 'million': False, 'secret': False, 'starring': False, 'clear': False, 'familiar': False, 'romance': True, 'intelligent': True, 'third': False, 'excellent': False, 'amazing': False, 'party': False, 'budget': False, 'eye': False, 'actress': True, 'prison': False, 'latest': False, 'means': False, 'company': False, 'towards': False, 'predictable': False, 'powerful': False, 'bob': False, 'beyond': True, 'visual': True, 'leaves': False, 'r': True, 'nature': False, 'following': False, 'villain': False, 'leaving': False, 'animated': False, 'low': False, 'b': False, 'bill': False, 'sam': False, 'filled': False, 'wars': False, 'questions': True, 'cinema': False, 'message': False, 'box': False, 'moving': False, 'country': False, 'usual': False, 'martin': False, 'definitely': False, 'add': False, 'large': False, 'clever': False, 'create': False, 'felt': False, 'stories': False, 'brilliant': True, 'ones': True, 'giant': False, 'situation': False, 'murphy': False, 'break': True, 'opens': False, 'scary': False, 'doubt': False, 'drug': False, 'bunch': False, 'thinking': False, 'solid': False, 'effect': True, 'learn': False, 'move': True, 'force': False, 'potential': False, 'seriously': False, 'follows': False, 'saying': False, 'huge': False, 'class': False, 'plan': False, 'agent': False, 'created': False, 'unlike': False, 'pay': False, 'non': False, 'married': False, 'mark': False, 'sweet': False, 'perfectly': False, 'ex': False, 'realize': False, 'audiences': False, 'took': False, 'decent': False, 'likely': False, 'dream': True, 'view': True, 'scott': False, 'subject': False, 'understand': False, 'happened': False, 'enjoyable': False, 'studio': False, 'immediately': False, 'open': False, 'e': False, 'points': True, 'heard': False, 'viewers': False, 'cameron': False, 'truman': False, 'bruce': False, 'frank': False, 'private': False, 'stay': True, 'fails': False, 'impossible': False, 'cold': False, 'richard': False, 'overall': False, 'merely': False, 'exciting': False, 'mess': False, 'chase': False, 'free': False, 'ten': False, 'neither': False, 'wanted': False, 'gun': False, 'appear': False, 'carter': False, 'escape': False, 'ultimately': False, 'fan': False, 'inside': True, 'favorite': False, 'modern': False, 'l': False, 'wedding': False, 'stone': False, 'trek': False, 'brought': False, 'trouble': False, 'otherwise': False, 'tim': False, '5': False, 'allen': False, 'bond': False, 'society': False, 'liked': False, 'dumb': False, 'musical': False, 'stand': False, 'political': False, 'various': False, 'talented': False, 'particular': False, 'west': False, 'state': False, 'keeps': False, 'english': False, 'silly': False, 'u': False, 'situations': False, 'park': False, 'teen': False, 'rating': False, 'slightly': True, 'steve': False, 'truth': False, 'air': False, 'element': False, 'joke': False, 'spend': False, 'key': False, 'biggest': False, 'members': False, 'effort': False, 'government': True, 'focus': False, 'eddie': False, 'soundtrack': False, 'hands': False, 'earlier': False, 'chan': False, 'purpose': False, 'today': False, 'showing': False, 'memorable': True, 'six': False, 'cannot': False, 'max': False, 'offers': False, 'rated': False, 'mars': False, 'heavy': False, 'totally': False, 'control': False, 'credit': False, 'fi': True, 'woody': False, 'ideas': False, 'sci': True, 'wait': False, 'sit': False, 'female': False, 'ask': False, 'waste': False, 'terrible': False, 'depth': False, 'simon': False, 'aspect': False, 'list': False, 'mary': False, 'sister': False, 'animation': False, 'entirely': False, 'fear': True, 'steven': False, 'moves': False, 'actual': False, 'army': False, 'british': False, 'constantly': False, 'fire': False, 'convincing': False, 'setting': False, 'gave': False, 'tension': True, 'street': False, '8': False, 'brief': False, 'ridiculous': False, 'cinematography': False, 'typical': False, 'nick': False, 'screenwriter': False, 'ability': False, 'spent': False, 'quick': False, 'violent': False, 'atmosphere': False, 'subtle': False, 'expected': False, 'fairly': False, 'seven': False, 'killing': False, 'tone': False, 'master': False, 'disaster': False, 'lots': False, 'thinks': False, 'song': False, 'cheap': False, 'suddenly': False, 'background': False, 'club': False, 'willis': False, 'whatever': False, 'highly': False, 'sees': False, 'complex': True, 'greatest': False, 'impact': False, 'beauty': False, 'front': False, 'humans': False, 'indeed': False, 'flat': False, 'grace': False, 'wrote': False, 'amusing': False, 'ii': False, 'mike': False, 'cute': False, 'dull': False, 'minor': False, 'recently': False, 'hate': False, 'outside': False, 'plenty': False, 'wish': False, 'godzilla': False, 'college': False, 'titanic': False, 'sounds': False, 'telling': False, 'sight': False, 'double': False, 'cinematic': False, 'queen': False, 'hold': False, 'meanwhile': False, 'awful': False, 'clearly': True, 'theme': False, 'hear': False, 'x': False, 'amount': True, 'baby': False, 'approach': False, 'dreams': False, 'shown': False, 'island': False, 'reasons': False, 'charm': False, 'miss': False, 'longer': False, 'common': False, 'sean': False, 'carry': False, 'believable': False, 'realistic': False, 'chemistry': False, 'possibly': False, 'casting': False, 'carrey': False, 'french': False, 'trailer': False, 'tough': False, 'produced': False, 'imagine': False, 'choice': False, 'ride': False, 'somewhere': False, 'hot': False, 'race': False, 'road': False, 'leader': False, 'thin': False, 'jerry': False, 'slowly': False, 'delivers': False, 'detective': False, 'brown': False, 'jackson': False, 'member': False, 'provide': False, 'president': False, 'puts': False, 'asks': True, 'critics': False, 'appearance': False, 'famous': False, 'okay': False, 'intelligence': True, 'energy': False, 'sent': False, 'spielberg': False, 'development': False, 'etc': False, 'language': False, 'blue': False, 'proves': False, 'vampire': False, 'seemingly': False, 'basic': False, 'caught': False, 'decide': False, 'opportunity': False, 'incredibly': False, 'images': False, 'band': False, 'j': False, 'writers': False, 'knew': False, 'interested': False, 'considering': False, 'boys': False, 'thanks': False, 'remains': False, 'climax': False, 'event': False, 'directing': False, 'conclusion': False, 'leading': True, 'ground': False, 'lies': True, 'forget': False, 'alive': False, 'tarzan': False, 'century': False, 'provides': True, 'trip': False, 'partner': False, 'central': True, 'tarantino': False, 'period': False, 'pace': True, 'worked': False, 'ready': False, 'date': False, 'thus': False, '1998': False, 'terrific': False, 'write': False, 'average': False, 'onto': True, 'songs': False, 'occasionally': False, 'doctor': False, 'stands': False, 'hardly': False, 'monster': False, 'led': False, 'mysterious': False, 'details': False, 'wasted': False, 'apart': False, 'aside': False, 'store': False, 'billy': False, 'boss': False, 'travolta': False, 'producer': False, 'pull': False, 'consider': False, 'pictures': False, 'becoming': False, 'cage': False, 'loud': False, 'looked': False, 'officer': False, 'twenty': False, 'system': False, 'contains': False, 'julia': False, 'subplot': True, 'missing': False, 'personality': False, 'building': True, 'learns': False, 'hong': False, 'la': False, 'apartment': False, '7': False, 'bizarre': False, 'powers': False, 'flaws': False, 'catch': False, 'lawyer': False, 'shoot': False, 'student': False, 'unique': False, '000': False, 'admit': False, 'concept': False, 'needed': False, 'thrown': False, 'christopher': False, 'laughing': False, 'green': False, 'twists': False, 'matthew': True, 'touch': False, 'waiting': False, 'victim': False, 'cover': False, 'machine': False, 'danny': False, 'mention': False, 'search': False, '1997': False, 'win': False, 'door': False, 'manner': False, 'train': False, 'saving': False, 'share': False, 'image': True, 'discovers': False, 'normal': False, 'cross': False, 'fox': False, 'returns': False, 'adult': False, 'adds': False, 'answer': False, 'adventure': False, 'lame': False, 'male': False, 'odd': False, 'singer': False, 'deserves': False, 'gore': False, 'states': False, 'include': False, 'equally': False, 'months': False, 'barely': False, 'directors': False, 'introduced': False, 'fashion': False, 'social': False, '1999': False, 'news': False, 'hair': False, 'dance': False, 'innocent': False, 'camp': False, 'teacher': False, 'became': False, 'sad': False, 'witch': False, 'includes': True, 'nights': False, 'jason': False, 'julie': False, 'latter': False, 'food': False, 'jennifer': False, 'land': False, 'menace': False, 'rate': False, 'storyline': True, 'contact': True, 'jean': False, 'elizabeth': False, 'fellow': False, 'changes': False, 'henry': False, 'hill': False, 'pulp': False, 'gay': False, 'tried': False, 'surprised': False, 'literally': True, 'walk': False, 'standard': False, '90': False, 'forward': False, 'wise': False, 'enjoyed': False, 'discover': True, 'pop': False, 'anderson': False, 'offer': False, 'recommend': False, 'public': False, 'drive': False, 'c': False, 'toy': False, 'charming': False, 'fair': False, 'chinese': False, 'rescue': False, 'terms': False, 'mouth': False, 'lucas': False, 'accident': False, 'dies': False, 'decided': False, 'edge': True, 'footage': True, 'culture': False, 'weak': False, 'presented': False, 'blade': False, 'younger': False, 'douglas': False, 'natural': False, 'born': False, 'generally': False, 'teenage': False, 'older': False, 'horrible': False, 'addition': False, 'sadly': False, 'creates': False, 'disturbing': False, 'roger': False, 'detail': False, 'devil': False, 'debut': False, 'track': False, 'developed': False, 'week': False, 'russell': False, 'attack': False, 'explain': False, 'rarely': False, 'fully': False, 'prove': False, 'exception': False, 'jeff': False, 'twist': False, 'gang': False, 'winning': False, 'jr': False, 'species': False, 'issues': True, 'fresh': False, 'rules': False, 'meaning': False, 'inspired': False, 'heroes': False, 'desperate': False, 'fighting': False, 'filmed': False, 'faces': False, 'alan': False, 'bright': False, 'ass': False, 'flying': False, 'kong': False, 'rush': False, 'forces': False, 'charles': False, 'numerous': False, 'emotions': False, 'involves': False, 'patrick': False, 'weird': False, 'apparent': False, 'information': False, 'revenge': False, 'jay': False, 'toward': False, 'surprising': False, 'twice': False, 'editing': False, 'calls': False, 'lose': False, 'vegas': False, 'stage': False, 'intended': False, 'gags': False, 'opinion': False, 'likes': False, 'crazy': False, 'owner': False, 'places': False, 'pair': False, 'genuine': False, 'epic': False, 'speak': False, 'throw': False, 'appeal': False, 'gibson': False, 'captain': False, 'military': False, '20': False, 'blair': False, 'nowhere': False, 'length': False, 'nicely': False, 'cause': False, 'pass': False, 'episode': False, 'kiss': False, 'arnold': False, 'please': False, 'phone': False, 'filmmaking': False, 'formula': False, 'boyfriend': False, 'talents': False, 'creating': False, 'kelly': False, 'buy': False, 'wide': False, 'fantasy': False, 'mood': False, 'heads': False, 'pathetic': False, 'lacks': False, 'loved': False, 'asked': False, 'mrs': False, 'witty': False, 'shakespeare': False, 'mulan': False, 'generation': False, 'affair': False, 'pieces': False, 'task': False, 'rare': False, 'kept': False, 'cameo': False, 'fascinating': True, 'ed': False, 'fbi': False, 'burton': False, 'incredible': False, 'accent': False, 'artist': False, 'superior': False, 'academy': False, 'thomas': False, 'spirit': False, 'technical': False, 'confusing': False, 'poorly': False, 'target': False, 'lover': False, 'woo': False, 'mentioned': False, 'theaters': False, 'plane': False, 'confused': False, 'dennis': False, 'rob': False, 'appropriate': False, 'christmas': False, 'considered': False, 'legend': False, 'shame': False, 'soul': False, 'matt': False, 'campbell': False, 'process': False, 'bottom': False, 'sitting': False, 'brain': False, 'creepy': True, '13': False, 'forever': False, 'dude': False, 'crap': False, 'superb': False, 'speech': False, 'ice': False, 'journey': True, 'masterpiece': False, 'intriguing': False, 'names': False, 'pick': False, 'speaking': False, 'virtually': False, 'award': False, 'worthy': False, 'marriage': False, 'deliver': False, 'cash': False, 'magic': False, 'respect': False, 'product': False, 'necessary': False, 'suppose': False, 'silent': False, 'pointless': False, 'station': False, 'affleck': False, 'dimensional': False, 'charlie': False, 'allows': False, 'avoid': False, 'meant': False, 'cops': False, 'attitude': False, 'relationships': False, 'hits': False, 'stephen': False, 'spends': False, 'relief': False, 'physical': False, 'count': False, 'reviews': True, 'appreciate': False, 'cliches': False, 'holds': True, 'pure': True, 'plans': False, 'limited': False, 'failed': False, 'pain': False, 'impression': False, 'unless': False, 'sub': False, 'total': False, 'creature': False, 'viewing': False, 'loves': False, 'princess': False, 'kate': False, 'rising': False, 'woods': True, 'baldwin': False, 'angry': False, 'drawn': False, 'step': False, 'matrix': False, 'themes': False, 'satire': False, 'arts': False, 'remake': False, 'wall': False, 'moral': False, 'color': False, 'ray': False, 'stuck': False, 'touching': False, 'wit': False, 'tony': False, 'hanks': False, 'continues': True, 'damn': False, 'nobody': False, 'cartoon': False, 'keeping': False, 'realized': False, 'criminal': False, 'unfunny': False, 'comedic': False, 'martial': False, 'disappointing': False, 'anti': False, 'graphic': False, 'stunning': True, 'actions': False, 'floor': False, 'emotion': True, 'soldiers': False, 'edward': False, 'comedies': False, 'driver': False, 'expectations': False, 'added': False, 'mad': False, 'angels': False, 'shallow': False, 'suspect': False, 'humorous': False, 'phantom': False, 'appealing': False, 'device': False, 'design': False, 'industry': False, 'reach': False, 'fat': False, 'blame': False, 'united': False, 'sign': False, 'portrayal': False, 'rocky': False, 'finale': False, 'grand': False, 'opposite': False, 'hotel': False, 'match': False, 'damme': False, 'speed': False, 'ok': False, 'loving': False, 'field': False, 'larry': False, 'urban': False, 'troopers': False, 'compared': False, 'apes': False, 'rose': False, 'falling': False, 'era': False, 'loses': False, 'adults': False, 'managed': False, 'dad': False, 'therefore': False, 'pg': True, 'results': False, 'guns': False, 'radio': True, 'lady': False, 'manage': False, 'spice': False, 'naked': False, 'started': True, 'intense': False, 'humanity': False, 'wonderfully': False, 'slasher': False, 'bland': False, 'imagination': False, 'walking': True, 'willing': False, 'horse': False, 'rent': False, 'mix': False, 'generated': False, 'g': False, 'utterly': False, 'scientist': True, 'washington': False, 'notice': False, 'players': False, 'teenagers': False, 'moore': False, 'board': False, 'price': False, 'frightening': False, 'tommy': False, 'spectacular': False, 'bored': False, 'jane': False, 'join': False, 'producers': False, 'johnny': False, 'zero': False, 'vampires': False, 'adaptation': True, 'dollars': False, 'parody': False, 'documentary': False, 'dvd': False, 'wayne': False, 'post': False, 'exist': False, 'matters': False, 'chosen': False, 'mel': False, 'attractive': False, 'plain': False, 'trust': False, 'safe': False, 'reading': False, 'hoping': False, 'protagonist': False, 'feelings': False, 'fate': False, 'finding': False, 'feet': False, 'visuals': False, 'spawn': False, 'compelling': False, 'hall': False, 'sympathetic': False, 'featuring': False, 'difference': False, 'professional': False, 'drugs': False, 'ford': False, 'shooting': False, 'gold': False, 'patch': False, 'build': False, 'boat': False, 'cruise': False, 'honest': False, 'media': False, 'flicks': False, 'bug': False, 'bringing': False, 'dangerous': False, 'watched': False, 'grant': False, 'smile': False, 'plus': True, 'decision': False, 'visually': False, 'allow': False, 'starship': False, 'roberts': False, 'dying': False, 'portrayed': False, 'turning': False, 'believes': False, 'changed': False, 'shock': False, 'destroy': False, '30': False, 'crowd': False, 'broken': False, 'tired': False, 'fail': False, 'south': False, 'died': False, 'cult': False, 'fake': False, 'vincent': False, 'identity': False, 'sexy': False, 'hunt': False, 'jedi': False, 'flynt': False, 'alex': False, 'engaging': False, 'serve': False, 'snake': False, 'yeah': False, 'expecting': False, '100': False, 'decade': False, 'ups': False, 'constant': False, 'current': False, 'survive': False, 'jimmy': False, 'buddy': False, 'send': False, 'brooks': False, 'goofy': False, 'likable': False, 'humour': False, 'technology': True, 'files': False, 'babe': False, 'aspects': False, 'presents': False, 'kills': False, 'supposedly': False, 'eight': False, 'sandler': False, 'hospital': False, 'test': False, 'hidden': False, 'brian': False, 'books': False, 'promise': False, 'determined': False, 'professor': False, 'welcome': True, 'pleasure': False, 'succeeds': False, 'individual': False, 'annie': False, 'mob': False, 'ted': False, 'virus': False, 'content': False, 'gary': False, 'direct': False, 'contrived': False, 'carpenter': False, 'scale': False, 'sick': False, 'nasty': False, 'conflict': False, 'haunting': False, 'ghost': False, 'filmmaker': False, 'japanese': False, 'helps': False, 'fare': False, 'lucky': False, 'ultimate': False, 'window': False, 'support': False, 'goal': False, 'provided': False, 'genius': False, 'winner': False, 'taylor': False, 'fantastic': False, 'faith': True, 'lynch': False, 'fit': False, 'catherine': False, 'ms': False, 'paced': False, 'breaks': False, 'al': False, 'frame': False, 'travel': False, 'badly': False, 'available': False, 'cares': False, 'reeves': False, 'crash': False, 'driving': False, 'press': False, 'seagal': False, 'amy': False, '9': False, 'headed': False, 'instance': False, 'excuse': False, 'offensive': False, 'narrative': False, 'fault': False, 'bus': False, 'f': False, 'extreme': False, 'miller': False, 'guilty': False, 'grows': False, 'overly': False, 'liners': False, 'forgotten': False, 'ahead': True, 'accept': False, 'porn': False, 'directly': False, 'helen': False, 'began': False, 'lord': False, 'folks': False, 'mediocre': False, 'bar': False, 'surface': False, 'super': False, 'failure': False, '6': False, 'acted': False, 'quiet': False, 'laughable': False, 'sheer': False, 'security': True, 'emotionally': False, 'season': False, 'stuart': False, 'jail': False, 'deals': False, 'cheesy': False, 'court': False, 'beach': False, 'austin': False, 'model': False, 'outstanding': False, 'substance': False, 'nudity': False, 'slapstick': False, 'joan': False, 'reveal': False, 'placed': False, 'check': False, 'beast': False, 'hurt': True, 'bloody': False, 'acts': False, 'fame': False, 'meeting': False, 'nuclear': False, '1996': False, 'strength': False, 'center': False, 'funniest': False, 'standing': False, 'damon': False, 'clich': False, 'position': False, 'desire': False, 'driven': False, 'seat': True, 'stock': False, 'wondering': False, 'realizes': False, 'dealing': True, 'taste': False, 'routine': False, 'comparison': False, 'cinematographer': False, 'seconds': False, 'singing': False, 'gangster': False, 'responsible': False, 'football': False, 'remarkable': False, 'hunting': False, 'adams': False, 'fly': False, 'suspects': False, 'treat': False, 'hopes': False, 'heaven': False, 'myers': False, 'struggle': False, 'costumes': False, 'beat': False, 'happening': False, 'skills': False, 'ugly': False, 'figures': False, 'thoroughly': False, 'ill': False, 'surprises': False, 'player': False, 'rival': True, 'guard': False, 'anthony': False, 'strike': False, 'community': False, 'streets': False, 'hopkins': False, 'ended': False, 'originally': False, 'sarah': False, 'creative': False, 'characterization': False, 'thankfully': False, 'growing': False, 'sharp': False, 'williamson': False, 'eccentric': True, 'explained': False, 'hey': False, 'claire': False, 'steal': False, 'inevitable': False, 'joel': False, 'core': False, 'sorry': False, 'built': False, 'anne': False, 'breaking': False, 'villains': False, 'critic': False, 'lets': False, 'visit': False, 'followed': False, 'serial': False, 'value': False, 'missed': False, 'oliver': False, 'hollow': False, 'sea': False, 'animal': False, 'freeman': False, 'animals': False, 'crystal': False, 'sidney': False, 'lacking': False, 'students': False, 'continue': False, 'extra': False, 'scorsese': False, 'church': False, 'stick': False, 'explanation': False, 'hip': False, 'quest': True, 'mistake': False, 'jump': False, 'fights': False, 'cusack': False, 'included': False, 'draw': False, '15': False, 'games': False, '1995': False, 'judge': False, 'gotten': False, 'chief': False, 'derek': False, 'thirty': False, 'record': False, 'everybody': False, 'veteran': False, 'develop': False, 'knowledge': False, 'serves': False, 'boogie': False, 'arrives': False, 'clooney': False, 'enter': False, 'russian': False, 'obsessed': False, 'vision': False, 'screenwriters': False, 'luck': False, 'holes': False, 'religious': True, 'witness': False, 'flashbacks': False, 'heavily': False, 'frequently': False, 'capable': False, 'armageddon': False, 'pacing': False, 'rise': False, 'mainly': False, 'fill': False, 'barry': False, 'schwarzenegger': False, 'clean': False, 'previously': False, 'grow': False, 'keaton': False, 'empty': False, 'synopsis': True, 'victims': False, 'adam': False, 'bed': False, 'lawrence': False, 'stallone': False, 'hunter': False, 'memory': False, 'suit': True, 'bobby': False, 'tragedy': False, 'saved': False, 'spot': False, 'unexpected': False, 'encounter': False, 'hearted': False, 'bacon': False, 'disappointment': False, 'bigger': False, 'noir': False, 'nicholson': False, 'evidence': True, 'relatively': False, 'morning': False, 'andrew': False, 'range': False, 'numbers': False, 'walter': False, 'vehicle': True, 'pulled': False, 'describe': False, 'cliched': False, 'sky': False, 'efforts': False, 'logic': False, 'verhoeven': False, 'assistant': False, 'existence': False, 'worker': False, 'freedom': False, 'theatre': False, 'wood': False, 'warm': False, 'fish': False, 'ripley': False, 'mental': False, 'study': True, 'justice': False, 'cliche': False, 'foot': False, 'jonathan': False, 'grown': False, 'unnecessary': False, 'rip': False, 'learned': False, 'skin': False, 'talks': False, 'ball': True, 'alice': False, 'roll': False, 'weeks': False, 'jon': False, 'courtroom': False, 'positive': True, 'putting': False, 'connection': False, 'london': False, 'angel': False, 'contrast': False, 'exact': False, 'fifteen': False, 'eric': False, 'prince': False, 'bound': False, 'traditional': False, 'regular': False, 'eve': False, 'niro': False, 'las': False, 'remain': False, 'anna': False, 'moved': False, 'asking': False, 'genuinely': False, 'rain': False, 'path': False, 'aware': False, 'causes': False, 'international': False}, 'pos')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Training**\n",
        "\n",
        "Now, we will create training and testing sets."
      ],
      "metadata": {
        "id": "wzcInCmlSxMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training set and Testing set\n",
        "train_data = feature_sets[:1600]\n",
        "test_data = feature_sets[1600:]"
      ],
      "metadata": {
        "id": "sT3xbrqiMxO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of training set\n",
        "len(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAGGoSKUS5Nx",
        "outputId": "89839225-150e-48d6-cf56-b8d81ab1c65e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1600"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of testing set\n",
        "len(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRxLyI7FS6-W",
        "outputId": "c91bfa7a-8362-4326-a7a5-51aa6fddce65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(1600/2000, 400/2000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6jwXl-7S8_p",
        "outputId": "2eb32e8b-c0ec-49d7-fc18-3581c6ea64ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8, 0.2)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be using the **Naive Bayes Classifier** for our training."
      ],
      "metadata": {
        "id": "rnkA1fvbTAA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the NaiveBayesClassifier from nltk\n",
        "from nltk import NaiveBayesClassifier\n",
        "\n",
        "# Creating an instance of our classifier and training the model\n",
        "base_model = NaiveBayesClassifier.train(train_data)"
      ],
      "metadata": {
        "id": "x85JoqCDS-Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing classify from nltk\n",
        "from nltk import classify\n",
        "\n",
        "# Calculating the accuracy of the base model \n",
        "accuracy_score = classify.accuracy(base_model, test_data)\n",
        "print(\"Accuracy Score of Base Model : {}%\".format(100 * accuracy_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwxyrgQES-E7",
        "outputId": "3ec2d21e-79b0-41ce-80d4-12c6e6017c87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score of Base Model : 77.75%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show 10 most informative features\n",
        "print(base_model.show_most_informative_features(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6wfgZYLS-B9",
        "outputId": "ba7e8c9f-ab7e-44a3-ae03-a188148fb458"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            "             outstanding = True              pos : neg    =     15.4 : 1.0\n",
            "                   damon = True              pos : neg    =     10.3 : 1.0\n",
            "                   mulan = True              pos : neg    =      8.4 : 1.0\n",
            "             wonderfully = True              pos : neg    =      6.9 : 1.0\n",
            "              ridiculous = True              neg : pos    =      6.3 : 1.0\n",
            "                  seagal = True              neg : pos    =      6.1 : 1.0\n",
            "                  wasted = True              neg : pos    =      6.1 : 1.0\n",
            "                    lame = True              neg : pos    =      5.7 : 1.0\n",
            "                   flynt = True              pos : neg    =      5.7 : 1.0\n",
            "               portrayed = True              pos : neg    =      5.3 : 1.0\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Other Classifiers**"
      ],
      "metadata": {
        "id": "oE3Y4XAhwSvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing scikit-learn module from NLTK (a wrapper for sklearn)\n",
        "from nltk.classify.scikitlearn import SklearnClassifier"
      ],
      "metadata": {
        "id": "RPGJVGBnTWsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets use some other types of Naive Bayes classifiers from sklearn\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
        "\n",
        "# Lets import some more classifiers\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC"
      ],
      "metadata": {
        "id": "gUZfMV4Tw2Xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multinomial Naive Bayes classifier\n",
        "multinomial_nb_model = SklearnClassifier(MultinomialNB())\n",
        "multinomial_nb_model.train(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DM_GMDCB0_yu",
        "outputId": "81761220-d192-4a7c-ef85-2fc36241e4a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SklearnClassifier(MultinomialNB())>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bernoulli Naive Bayes classifier\n",
        "bernoulli_nb_model = SklearnClassifier(BernoulliNB())\n",
        "bernoulli_nb_model.train(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8abBXNJ1JV0",
        "outputId": "469a41aa-76ed-48f4-9d85-fb7b4637d979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SklearnClassifier(BernoulliNB())>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression classifier\n",
        "logit_model = SklearnClassifier(LogisticRegression())\n",
        "logit_model.train(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B3rI-tI1MG2",
        "outputId": "75115383-b7f3-4bdb-899b-1b0b002b3a5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SklearnClassifier(LogisticRegression())>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stochastic Gradient Descent classifier\n",
        "sgd_model = SklearnClassifier(SGDClassifier())\n",
        "sgd_model.train(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-SIyo021MDm",
        "outputId": "08acaeca-be33-4e65-d59a-89e525b4b702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SklearnClassifier(SGDClassifier())>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# C-Support Vector Classification classifier\n",
        "svc_model = SklearnClassifier(SVC())\n",
        "svc_model.train(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wieFadI_1MBU",
        "outputId": "c0d4f938-5b59-4ea3-e98a-623b6eaf9e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SklearnClassifier(SVC())>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Support Vector Classification classifier\n",
        "linear_svc_model = SklearnClassifier(LinearSVC())\n",
        "linear_svc_model.train(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ks5xQiU1L-B",
        "outputId": "43bca133-8f6d-4451-f383-e3d03b7be74d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SklearnClassifier(LinearSVC())>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Nu-Support Vector Classification classifier\n",
        "nu_svc_model = SklearnClassifier(NuSVC())\n",
        "nu_svc_model.train(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hO83ZoZx1L7s",
        "outputId": "0d715b00-1802-4a8d-e3b5-74414da9a797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SklearnClassifier(NuSVC())>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy Score of Base Model : {}%\".format(100 * accuracy_score))\n",
        "print(\"MultinomialNB Model Accuracy Score: {}%\".format(100 * classify.accuracy(multinomial_nb_model, test_data)))\n",
        "print(\"BernoulliNB Model Accuracy Score: {}%\".format(100 * classify.accuracy(bernoulli_nb_model, test_data)))\n",
        "print(\"LogisticRegression Model Accuracy Score: {}%\".format(100 * classify.accuracy(logit_model, test_data)))\n",
        "print(\"SGDClassifier Model Accuracy Score: {}%\".format(100 * classify.accuracy(sgd_model, test_data)))\n",
        "print(\"SVC Model Accuracy Score: {}%\".format(100 * classify.accuracy(svc_model, test_data)))\n",
        "print(\"LinearSVC Model Accuracy Score: {}%\".format(100 * classify.accuracy(linear_svc_model, test_data)))\n",
        "print(\"NuSVC Model Accuracy Score: {}%\".format(100 * classify.accuracy(nu_svc_model, test_data)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khCVJ9rW1L5D",
        "outputId": "274af74d-c000-4f46-ac76-fcfbe293cd9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score of Base Model : 77.75%\n",
            "MultinomialNB Model Accuracy Score: 80.75%\n",
            "BernoulliNB Model Accuracy Score: 77.75%\n",
            "LogisticRegression Model Accuracy Score: 81.75%\n",
            "SGDClassifier Model Accuracy Score: 82.75%\n",
            "SVC Model Accuracy Score: 86.0%\n",
            "LinearSVC Model Accuracy Score: 80.25%\n",
            "NuSVC Model Accuracy Score: 85.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YJtOc6zK0fmu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
