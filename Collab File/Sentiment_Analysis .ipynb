{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Importing the required modules**"
      ],
      "metadata": {
        "id": "9qHzqY7xLTeC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5FIGu0rIQG3"
      },
      "outputs": [],
      "source": [
        "# Importing the NLTK library and Random module\n",
        "import nltk\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2EHKLtzIpwo"
      },
      "outputs": [],
      "source": [
        "# Downloading all the NLTK files\n",
        "nltk.download_shell()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4NajwlD4uFN"
      },
      "outputs": [],
      "source": [
        "# Importing tokenizers\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRLOzW7L342l"
      },
      "source": [
        "**Uploading the text files in google colab**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "63kNZ2xKfGUv",
        "outputId": "2da2ac3a-fc3e-4e32-cc68-4377cd3cacbc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-66a0dc13-a876-4a4b-8644-d3e620877436\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-66a0dc13-a876-4a4b-8644-d3e620877436\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving negative.txt to negative.txt\n",
            "Saving positive.txt to positive.txt\n"
          ]
        }
      ],
      "source": [
        "# Improting file from google colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95y37wp94Cl9"
      },
      "source": [
        "**Opening and reading the required text files (short reviews)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCNFq5ieiPvu"
      },
      "outputs": [],
      "source": [
        "# opening and reading the required text files\n",
        "short_positives = open(\"/content/positive.txt\", mode='r', encoding='ISO-8859-1').read()\n",
        "short_negatives = open(\"/content/negative.txt\", mode='r', encoding='ISO-8859-1').read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjE_NwWC4J9L"
      },
      "source": [
        "**Storing the short reviews in documents and all word tokens lists**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an empty list for storing the documents\n",
        "documents = []\n",
        "\n",
        "# Creating an empty list for storing appropriate word tokens\n",
        "all_words_tokens = []\n",
        "\n",
        "# Allowing for only adjectives as PoS tag for our reviews\n",
        "allowed_pos_tag = [\"J\"]"
      ],
      "metadata": {
        "id": "5k_ZCKAPwHVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterating through each review splitting with a new line in the short_positives\n",
        "for rev in short_positives.split('\\n'):\n",
        "\n",
        "  # appending reviews in the documents list with 'pos' tag\n",
        "  documents.append((rev, \"pos\"))\n",
        "\n",
        "  # creating word tokens of the reviews\n",
        "  word_tokens = word_tokenize(rev)\n",
        "\n",
        "  # pos tagging of the word tokens\n",
        "  pos = nltk.pos_tag(word_tokens)\n",
        "\n",
        "  # Taking only the allowed pos tags and appending\n",
        "  # them int he all_words_tokens list\n",
        "  for token in pos:\n",
        "    if token[1][0] in allowed_pos_tag:\n",
        "      all_words_tokens.append(token[0].lower())"
      ],
      "metadata": {
        "id": "mwojLG_hzOci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterating through each review splitting with a new line in the short_negatives\n",
        "for rev in short_negatives.split('\\n'):\n",
        "\n",
        "  # appending reviews in the documents list with 'pos' tag\n",
        "  documents.append((rev, \"neg\"))\n",
        "\n",
        "  # creating word tokens of the reviews\n",
        "  word_tokens = word_tokenize(rev)\n",
        "\n",
        "  # pos tagging of the word tokens\n",
        "  pos = nltk.pos_tag(word_tokens)\n",
        "\n",
        "  # Taking only the allowed pos tags and appending\n",
        "  # them int he all_words_tokens list\n",
        "  for token in pos:\n",
        "    if token[1][0] in allowed_pos_tag:\n",
        "      all_words_tokens.append(token[0].lower())"
      ],
      "metadata": {
        "id": "va8GiPsI55d9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing pickle module\n",
        "import pickle"
      ],
      "metadata": {
        "id": "8hba_F386qlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the documents list\n",
        "save_docs = open(\"documents.pickle\", \"wb\")\n",
        "pickle.dump(documents, save_docs)\n",
        "save_docs.close()"
      ],
      "metadata": {
        "id": "GJ8fw7Nw7IJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoL9bZI_NBA3"
      },
      "source": [
        "**Frequency Distribution of all the word tokens**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKiJ8eaoI6qB"
      },
      "outputs": [],
      "source": [
        "# Get the frequency distribition of all the words\n",
        "all_words_freq = nltk.FreqDist(all_words_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTwDj90LLJRz",
        "outputId": "ba704fb9-42f7-40ea-cbfc-0440d7f90a59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6178\n"
          ]
        }
      ],
      "source": [
        "# Print out the length of the all frequent words list\n",
        "print(len(all_words_freq))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WG1uexfqna4E",
        "outputId": "9603a6e2-2be3-4a5a-b624-9b5c147bae7b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('good', 369),\n",
              " ('more', 331),\n",
              " ('little', 265),\n",
              " ('funny', 245),\n",
              " ('much', 234),\n",
              " ('bad', 234),\n",
              " ('best', 208),\n",
              " ('new', 206),\n",
              " ('own', 185),\n",
              " ('many', 183)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Printing out the top 10 most common words\n",
        "all_words_freq.most_common(10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking the 5000 most common words\n",
        "most_common_word_tokens = all_words_freq.most_common(5000)"
      ],
      "metadata": {
        "id": "QxHpSMLR8PH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4L9W2Aa3LfKz",
        "outputId": "c7ea64e8-ecf1-4cff-d682-04bbd8b0a00d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['good', 'more', 'little', 'funny', 'much', 'bad', 'best', 'new', 'own', 'many']\n"
          ]
        }
      ],
      "source": [
        "# Since the elements of the most_common_word_tokens list are in the form of tuples,\n",
        "# we need to extract the keys of each tuple to get the words as word features\n",
        "word_features = [word[0] for word in most_common_word_tokens]\n",
        "\n",
        "# Print out the top 10 word features\n",
        "print(word_features[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vhfUlG1LfH8",
        "outputId": "3b72eb6a-fce0-4f8f-9360-566166956d19"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Length of the word_features list\n",
        "len(word_features)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the word_features list\n",
        "save_word_features = open(\"word_features5k.pickle\", \"wb\")\n",
        "pickle.dump(word_features, save_word_features)\n",
        "save_word_features.close()"
      ],
      "metadata": {
        "id": "jGe8psDW-sBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw9IVYcNLl-3"
      },
      "source": [
        "**Creating a Feature Set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boR_Xr5ULfEx"
      },
      "outputs": [],
      "source": [
        "# Creating a function to get the features (words) in a dictionary\n",
        "def doc_features(doc):\n",
        "\n",
        "    doc_words = word_tokenize(doc)\n",
        "\n",
        "    # creating an empty features list\n",
        "    features = []\n",
        "\n",
        "    # Will iterate through all the words present in the word_features list\n",
        "    for word in word_features:\n",
        "\n",
        "        # Get that word and see its presence in the document (will return a bollean value)\n",
        "        features[word] = (word in doc_words)\n",
        "\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyg_ynFJLe-L"
      },
      "outputs": [],
      "source": [
        "# Now, we are going to create a feature set which will contain the word features of the review and its correspoding category\n",
        "feature_sets = [(doc_features(review), category) for (review, category) in documents]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffling the feature_sets\n",
        "random.shuffle(feature_sets)"
      ],
      "metadata": {
        "id": "kHu38KsZnPb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving feature sets\n",
        "featuresets_f = open(\"featuresets.pickle\", \"wb\")\n",
        "pickle.dump(feature_sets, featuresets_f)\n",
        "featuresets_f.close()"
      ],
      "metadata": {
        "id": "GKhprTQXGsiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_inAXDG7-pZd",
        "outputId": "d31fe738-98aa-4303-f013-07edfd10cc2d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10664"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Length of the feature_sets\n",
        "len(feature_sets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzcInCmlSxMi"
      },
      "source": [
        "**Model Training**\n",
        "\n",
        "Now, we will create training and testing sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sT3xbrqiMxO3"
      },
      "outputs": [],
      "source": [
        "# Training set and Testing set\n",
        "train_data = feature_sets[:8000]\n",
        "test_data = feature_sets[8000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAGGoSKUS5Nx",
        "outputId": "ed5aebb3-7854-412a-827e-e7fee306e326"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8000"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Length of training set\n",
        "len(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRxLyI7FS6-W",
        "outputId": "ea08c19a-baef-4a65-9eb2-3c48f3df6dc2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2664"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# Length of testing set\n",
        "len(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6jwXl-7S8_p",
        "outputId": "cbe58648-cea1-4187-bba6-159dc8d98e05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7501875468867217, 0.24981245311327832)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "(len(train_data)/len(feature_sets), len(test_data)/len(feature_sets))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnkA1fvbTAA3"
      },
      "source": [
        "We will be using the **Naive Bayes Classifier** for our training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x85JoqCDS-Ia"
      },
      "outputs": [],
      "source": [
        "# Importing the NaiveBayesClassifier from nltk\n",
        "from nltk import NaiveBayesClassifier\n",
        "\n",
        "# Creating an instance of our classifier and training the model\n",
        "base_model = NaiveBayesClassifier.train(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwxyrgQES-E7",
        "outputId": "4d7045f5-93f9-46c4-8e0b-707f4b596107"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score of Base Model : 72.07207207207207%\n"
          ]
        }
      ],
      "source": [
        "# Importing classify from nltk\n",
        "from nltk import classify\n",
        "\n",
        "# Calculating the accuracy of the base model\n",
        "accuracy_score = classify.accuracy(base_model, test_data)\n",
        "print(\"Accuracy Score of Base Model : {}%\".format(100 * accuracy_score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6wfgZYLS-B9",
        "outputId": "fff0204f-b404-47be-9178-cceda8cb7f1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            "               wonderful = True              pos : neg    =     17.1 : 1.0\n",
            "              engrossing = True              pos : neg    =     16.5 : 1.0\n",
            "               inventive = True              pos : neg    =     14.4 : 1.0\n",
            "                 routine = True              neg : pos    =     12.2 : 1.0\n",
            "                powerful = True              pos : neg    =     12.2 : 1.0\n",
            "                    imax = True              pos : neg    =     11.8 : 1.0\n",
            "                  sexual = True              pos : neg    =     11.8 : 1.0\n",
            "             masterpiece = True              pos : neg    =     11.1 : 1.0\n",
            "             mesmerizing = True              pos : neg    =     11.1 : 1.0\n",
            "                    loud = True              neg : pos    =     10.9 : 1.0\n",
            "                  boring = True              neg : pos    =     10.6 : 1.0\n",
            "              refreshing = True              pos : neg    =     10.4 : 1.0\n",
            "                    flat = True              neg : pos    =     10.1 : 1.0\n",
            "                touching = True              pos : neg    =      9.9 : 1.0\n",
            "                   urban = True              pos : neg    =      9.7 : 1.0\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Show 15 most informative features\n",
        "print(base_model.show_most_informative_features(15))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving base_model (Naive Bayes Classifier)\n",
        "save_classifier = open(\"base_model_naivebayes5k.pickle\",\"wb\")\n",
        "pickle.dump(base_model, save_classifier)\n",
        "save_classifier.close()"
      ],
      "metadata": {
        "id": "B5piKR-JAYgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Other Classifiers**"
      ],
      "metadata": {
        "id": "XSwJlh4RvOoE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPGJVGBnTWsR"
      },
      "outputs": [],
      "source": [
        "# Importing scikit-learn module from NLTK (a wrapper for sklearn)\n",
        "from nltk.classify.scikitlearn import SklearnClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUctZnGu31m1"
      },
      "outputs": [],
      "source": [
        "# Lets use some other types of Naive Bayes classifiers from sklearn\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
        "\n",
        "# Lets import some more classifiers\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2w6iQG5v32tb",
        "outputId": "94e0b8f3-5bec-4026-8680-a880e953a002"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SklearnClassifier(MultinomialNB())>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# Multinomial Naive Bayes classifier\n",
        "multinomial_nb_model = SklearnClassifier(MultinomialNB())\n",
        "multinomial_nb_model.train(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOuew33s32mk",
        "outputId": "6a88d076-25ee-4fc0-8e90-b3bd7b025001"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SklearnClassifier(BernoulliNB())>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# Bernoulli Naive Bayes classifier\n",
        "bernoulli_nb_model = SklearnClassifier(BernoulliNB())\n",
        "bernoulli_nb_model.train(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlekKPU532ju",
        "outputId": "e70110a0-0ec8-42cf-e745-a7f2a35e92ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SklearnClassifier(SGDClassifier())>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# Stochastic Gradient Descent classifier\n",
        "sgd_model = SklearnClassifier(SGDClassifier())\n",
        "sgd_model.train(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqkxjbQZ32cW",
        "outputId": "54411bc1-5e37-4129-f0e7-e0bf3b9d19e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SklearnClassifier(LinearSVC())>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# Linear Support Vector Classification classifier\n",
        "linear_svc_model = SklearnClassifier(LinearSVC())\n",
        "linear_svc_model.train(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Nu-Support Vector Classification classifier\n",
        "nu_svc_model = SklearnClassifier(NuSVC())\n",
        "nu_svc_model.train(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1hXamg7AGGu",
        "outputId": "0f9e788e-d275-4bcd-eeb6-2d639cc8e8b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SklearnClassifier(NuSVC())>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uwsfZ2Y32Wx",
        "outputId": "e05954c1-e032-4536-f76b-f1cdf4a102b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score of Base Model (Naive Bayes) : 72.07207207207207%\n",
            "MultinomialNB Model Accuracy Score: 71.69669669669669%\n",
            "BernoulliNB Model Accuracy Score: 71.47147147147147%\n",
            "SGDClassifier Model Accuracy Score: 70.08258258258259%\n",
            "LinearSVC Model Accuracy Score: 68.88138138138137%\n",
            "NuSVC Model Accuracy Score: 71.05855855855856%\n"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy Score of Base Model (Naive Bayes) : {}%\".format(100 * accuracy_score))\n",
        "print(\"MultinomialNB Model Accuracy Score: {}%\".format(100 * classify.accuracy(multinomial_nb_model, test_data)))\n",
        "print(\"BernoulliNB Model Accuracy Score: {}%\".format(100 * classify.accuracy(bernoulli_nb_model, test_data)))\n",
        "print(\"SGDClassifier Model Accuracy Score: {}%\".format(100 * classify.accuracy(sgd_model, test_data)))\n",
        "print(\"LinearSVC Model Accuracy Score: {}%\".format(100 * classify.accuracy(linear_svc_model, test_data)))\n",
        "print(\"NuSVC Model Accuracy Score: {}%\".format(100 * classify.accuracy(nu_svc_model, test_data)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving Multinomial Naive Bayes classifier\n",
        "save_classifier = open(\"multinomial_nb_model5k.pickle\",\"wb\")\n",
        "pickle.dump(multinomial_nb_model, save_classifier)\n",
        "save_classifier.close()"
      ],
      "metadata": {
        "id": "hkmiK5IAFAZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving Bernoulli Naive Bayes classifier\n",
        "save_classifier = open(\"bernoulli_nb_model5k.pickle\",\"wb\")\n",
        "pickle.dump(bernoulli_nb_model, save_classifier)\n",
        "save_classifier.close()"
      ],
      "metadata": {
        "id": "Dx3b-RhNFBNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving Stochastic Gradient Descent classifier\n",
        "save_classifier = open(\"sgd_model5k.pickle\",\"wb\")\n",
        "pickle.dump(sgd_model, save_classifier)\n",
        "save_classifier.close()"
      ],
      "metadata": {
        "id": "4ebFonlbFB3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving Linear Support Vector Classification classifier\n",
        "save_classifier = open(\"linear_svc_model5k.pickle\",\"wb\")\n",
        "pickle.dump(linear_svc_model, save_classifier)\n",
        "save_classifier.close()"
      ],
      "metadata": {
        "id": "dmK93VxXFCXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving Nu-Support Vector Classification classifier\n",
        "save_classifier = open(\"nu_svc_model5k.pickle\",\"wb\")\n",
        "pickle.dump(nu_svc_model, save_classifier)\n",
        "save_classifier.close()"
      ],
      "metadata": {
        "id": "mdZ276-1GSPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**After creating the sentiment module and saving it as sentiment_module.py, we will now import the module**"
      ],
      "metadata": {
        "id": "_axnchBm19PP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "zpqTlPH8RTwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Colab\\ Notebooks/NLP\\ Internship\\ /Data/sentiment_module.py /content"
      ],
      "metadata": {
        "id": "IC3S0uqARdwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the sentiment moduel\n",
        "import sentiment_module as sm"
      ],
      "metadata": {
        "id": "T686DGkfUBDn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "878949a8-4f6a-46eb-ad26-ef2647b89f88"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calling the method of the sentiment module\n",
        "sm.give_sentiment(\"This is an awesome movie. The direction was brilliant, the acting was perfect and I loved every bit of it.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Q1HprY82Q4S",
        "outputId": "82d7e071-929f-46d8-85a9-b34c5b2e9779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('pos', 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sm.give_sentiment(\"This is a bad movie. I didn't like it at all. The acting was not that good and the videography was utter disappointment.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHtEbaR14QkC",
        "outputId": "3f35bf37-8d17-40fb-9f18-2e91c3667efc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('neg', 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sm.give_sentiment(\"I understand the language was meant for the broad audience to understand but the producers could have made a better attempt at having the cast take on a heavier Italian accent. That was strike one for me. The acting was not atrocious but the script was unnecessarily extended in many acts, strike two. Too many blips in the storyline. There was no smooth transition of the time period progressions of Ferrucio's life, strike three. I know this was a direct to video movie but there was a lot of potential, A LOT of potential for this and it was a complete failure. Do better. Hopefully a different director/producer/writer/studio can portray the life of Lamborghini appropriately. You already are beat with the new Ferrari movie that isn't even out yet.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTphBQhX4VNv",
        "outputId": "be77916b-2bdb-48a6-dc9a-bb210760c620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('neg', 0.8)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sm.give_sentiment(\"very beautiful\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhUtzYUNOgS2",
        "outputId": "cf167530-6e0d-43aa-e8ff-9b07d1ee7ab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('pos', 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sm.give_sentiment(\"good film\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQnLt8dbRevN",
        "outputId": "48ca1da5-44c4-4398-c273-271e091d5c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('neg', 0.6)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sm.give_sentiment(\"This was the best movie.\")"
      ],
      "metadata": {
        "id": "zPL5ECaF4gJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a7f9c15-ad16-478b-a460-59b8afc057a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('pos', 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sm.give_sentiment(\"This movie was awesome! The acting was great, plot was wonderful, and there were pythons...so yea!\"))\n",
        "print(sm.give_sentiment(\"This movie was utter junk. There were absolutely 0 pythons. I don't see what the point was at all. Horrible movie, 0/10\"))"
      ],
      "metadata": {
        "id": "u5cWpLCLR2SZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2774156e-c279-4b08-8482-7d7e6d7a8f64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('pos', 1.0)\n",
            "('neg', 1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5RlDY7fhOVjr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}